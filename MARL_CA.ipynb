{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd00900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import random\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b848d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_begin = 13\n",
    "age_end = 100\n",
    "risk_groups = ['HM', 'HF', 'MSM']\n",
    "num_risk = 3\n",
    "age_groups = 88\n",
    "number_of_risk_groups = 3\n",
    "number_of_compartments = 22\n",
    "dt = 1/12\n",
    "num_age = 88\n",
    "num_comp = number_of_compartments-2\n",
    "prep_efficiency = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "unaware_index = (1,5,9,13,17)\n",
    "aware_no_care_index = (2,6,10,14,18)\n",
    "ART_VLS_index = (3,4,7,8,11,12,15,16,19,20)\n",
    "VLS_index = (4,8,12,16,20)\n",
    "\n",
    "pop_growth_rate = 0\n",
    "\n",
    "gamma = np.array([[0.5,0.5,0.5,0.5,1],\n",
    "                  [0.5,0.5,0.5,0.5,1],\n",
    "                  [0.5,0.5,0.5,0.5,1]])\n",
    "\n",
    "scaling_factor_dropout = np.array([[1,1,1,1,1,1,1,1,0,0],\n",
    "                                   [1,1,1,1,1,1,1,1,0,0],\n",
    "                                   [1,1,1,1,1,1,1,1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jurisdictions = [6001,6037,6059,6065,6067,6071,6073,6]\n",
    "num_jur = len(all_jurisdictions)\n",
    "\n",
    "cluster1 = [6001]\n",
    "cluster2 = [6037]\n",
    "cluster3 = [6059]\n",
    "cluster4 = [6065]\n",
    "cluster5 = [6067]\n",
    "cluster6 = [6071]\n",
    "cluster7 = [6073]\n",
    "cluster8 = [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb12a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array_cluster = np.zeros((num_jur, number_of_risk_groups, age_groups, number_of_compartments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ab66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for jur in range(len(all_jurisdictions)):\n",
    "\n",
    "    df1 = pd.read_excel('jurisdiction_pop_dist.xlsx', sheet_name=str(all_jurisdictions[jur]), index_col=0)\n",
    "    data_array_cluster[jur] = df1.iloc[:,3:].to_numpy().reshape(3,88,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pop = np.apply_over_axes(np.sum, data_array_cluster, [1,2,3]).reshape(num_jur,)\n",
    "total_pop = np.array([int(x) for x in total_pop])\n",
    "\n",
    "total_msm = list(np.apply_over_axes(np.sum, data_array_cluster, [2,3]).reshape(num_jur,3)[:,2])\n",
    "total_msm = np.array([int(x) for x in total_msm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1_index = np.array([0])\n",
    "cluster2_index = np.array([1])\n",
    "cluster3_index = np.array([2])\n",
    "cluster4_index = np.array([3])\n",
    "cluster5_index = np.array([4])\n",
    "cluster6_index = np.array([5])\n",
    "cluster7_index = np.array([6])\n",
    "cluster8_index = np.array([7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66bc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = pd.read_excel('Prep values.xlsx')\n",
    "\n",
    "df_prep_clus = df_prep.loc[df_prep['FIPS'].isin(all_jurisdictions)]\n",
    "\n",
    "jur_name = df_prep_clus['JUR'].to_list()\n",
    "df_prep_clus['Total MSM'] = total_msm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_values = np.zeros((num_jur,num_risk))\n",
    "prep_rates_clus = df_prep_clus['Prep'].values\n",
    "prep_eligible = df_prep_clus['PrEP Eligible'].values\n",
    "prep_values[:,2] = prep_rates_clus/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baea795",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixing_excel = 'JURI_mixing_weightedBydistance-6-3-2021.xlsx'\n",
    "\n",
    "mixing_df_hm = pd.read_excel(mixing_excel, sheet_name='HETM_mixing')\n",
    "mixing_df_hf = pd.read_excel(mixing_excel, sheet_name='HETF_mixing')\n",
    "mixing_df_msm = pd.read_excel(mixing_excel, sheet_name='MSM_mixing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b72aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixing_df_hm = mixing_df_hm[['FIPS', 6001,6037,6059,6065,6067,6071,6073,6]]\n",
    "mixing_df_hf = mixing_df_hf[['FIPS', 6001,6037,6059,6065,6067,6071,6073,6]]\n",
    "mixing_df_msm = mixing_df_msm[['FIPS', 6001,6037,6059,6065,6067,6071,6073,6]]\n",
    "\n",
    "mixing_hm = mixing_df_hm.loc[mixing_df_hm['FIPS'].isin(all_jurisdictions)]\n",
    "mixing_hf = mixing_df_hf.loc[mixing_df_hf['FIPS'].isin(all_jurisdictions)]\n",
    "mixing_msm = mixing_df_msm.loc[mixing_df_msm['FIPS'].isin(all_jurisdictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e195b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_array = mixing_hm.values[:,1:]\n",
    "hf_array = mixing_hf.values[:,1:]\n",
    "msm_array = mixing_msm.values[:,1:]\n",
    "\n",
    "hm_sum = np.sum(hm_array, axis=1)\n",
    "hf_sum = np.sum(hf_array, axis=1)\n",
    "msm_sum = np.sum(msm_array, axis=1)\n",
    "\n",
    "hm_array_scaled = hm_array / hm_sum[:,np.newaxis]\n",
    "hf_array_scaled = hf_array / hf_sum[:,np.newaxis]\n",
    "msm_array_scaled = msm_array / msm_sum[:,np.newaxis]\n",
    "\n",
    "mixing_matrix = np.zeros((num_risk,len(all_jurisdictions), len(all_jurisdictions)))\n",
    "\n",
    "mixing_matrix[0,:,:] = hm_array_scaled[:,:]\n",
    "mixing_matrix[1,:,:] = hf_array_scaled[:,:]\n",
    "mixing_matrix[2,:,:] = msm_array_scaled[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d62a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_age_mixing_mat(age_mat, age_begin, age_end):\n",
    "    \n",
    "    A1 = age_mat.values.reshape(8,8)    # age_mat- pandas dataframe, reshape(8,8) gives array of values excluding 1st row i.e. column name(age)\n",
    "    #print(age_mat.values.shape)\n",
    "    \n",
    "    A = age_mat.columns.values         # gives (8,) array of column names (age)\n",
    "    B = np.append(A, age_end+1)        # gives array of (9,1) with last element age_end+1\n",
    "    \n",
    "    \n",
    "    B1 = B-age_begin                   # new array of B-age_begin (difference in age)\n",
    "    #print(B, B1)\n",
    "    \n",
    "    #print(B1)\n",
    "    \n",
    "    C1 = np.empty([0,A.shape[0]])      #empty array of (0,8)\n",
    "    D1 = np.zeros((A.shape[0]))        # array with zeros (8,) 1d array\n",
    "    \n",
    "    F1 =np.array([])\n",
    "    for i in range(len(B1)-1):\n",
    "        D1[i] = int(B1[i+1]-B1[i])\n",
    "        F1 = np.append(F1, np.repeat(D1[i], D1[i]))\n",
    "    #print(F1)\n",
    "    D1 = D1.astype(int)\n",
    "    \n",
    "    for i in range(len(A1)):\n",
    "        res1 = np.tile(A1[i],(D1[i],1))\n",
    "        C1 = np.vstack((C1, res1))\n",
    "    H1 = np.empty([0,88])\n",
    "    \n",
    "    for i in range(C1.shape[0]):\n",
    "        res3 = np.array([])\n",
    "        for j in range(C1.shape[1]):\n",
    "            res3 = np.append( res3, (np.repeat(C1[i,j],D1[j])))\n",
    "        H1 = np.vstack((H1, res3))\n",
    "    \n",
    "           \n",
    "    G1 = np.zeros((88,88))\n",
    "    for i in range(H1.shape[0]):\n",
    "        G1[i] = H1[i]/F1\n",
    "    \n",
    "    age_mat = G1/100\n",
    "    \n",
    "    return(age_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_new_inf_input(age_begin, age_end, risk_groups):\n",
    "    \n",
    "    path = os.getcwd()\n",
    "    \n",
    "    num_risk_groups = len(risk_groups)\n",
    "    num_age_groups = age_end-age_begin+1\n",
    "    \n",
    "    excel = 'input_new_infections.xlsx'\n",
    "    \n",
    "    \n",
    "    \"\"\"###\"\"\"\n",
    "    q = pd.read_excel(excel, sheet_name='qmat').values.reshape(22,22)\n",
    "    #print(\"\\nNUMPY READ\",q, q.shape, np.sum(q))\n",
    "    \n",
    "    \"\"\"###\"\"\"\n",
    "    Age_hm = pd.read_excel(excel, sheet_name='A_hm')\n",
    "    \n",
    "    Age_hf = pd.read_excel(excel, sheet_name='A_hf')\n",
    "    \n",
    "    Age_msm = pd.read_excel(excel, sheet_name='A_msm')\n",
    "    \n",
    "    \n",
    "    A_hm = generate_age_mixing_mat(Age_hm, age_begin, age_end)\n",
    "    A_hf = generate_age_mixing_mat(Age_hf, age_begin, age_end)\n",
    "    A_msm = generate_age_mixing_mat(Age_msm, age_begin, age_end)\n",
    "    \n",
    "    age_mixing_final_mat = np.vstack((A_hm, A_hf, A_msm)).reshape(num_risk_groups,num_age_groups,num_age_groups)\n",
    "    \n",
    "    \"\"\"###\"\"\"\n",
    "    pi = pd.read_excel(excel, sheet_name='pi').values.reshape(20)\n",
    "    \n",
    "    \"\"\"###\"\"\"\n",
    "    num_sex_acts = pd.read_excel(excel, sheet_name='num_sex_acts') #female upper, female lower, male upper, male lower\n",
    "    number_of_sex_acts_risk_age = np.zeros((num_risk_groups,num_age_groups))\n",
    "    sex_act_calibration_param = [0.44, 90000000000000000, 90000000000000000]\n",
    "    \n",
    "    for risk in range(num_risk_groups):\n",
    "        current_risk_group = risk_groups[risk]\n",
    "        for age_index in range(num_age_groups):\n",
    "            current_age = age_index+age_begin\n",
    "    \n",
    "            if((current_risk_group == 'HM') | (current_risk_group == \"MSM\") | (current_risk_group == \"MSMIDU\") | (current_risk_group == \"IDUM\")):\n",
    "                upper = num_sex_acts[(num_sex_acts['Age_group'] == current_age)].Male_Upper.values\n",
    "                lower = num_sex_acts[(num_sex_acts['Age_group'] == current_age)].Male_Lower.values\n",
    "                \n",
    "            elif((current_risk_group == 'HF') | (current_risk_group == \"IDUF\")):\n",
    "                upper = num_sex_acts[(num_sex_acts['Age_group'] == current_age)].Female_Upper.values\n",
    "                lower = num_sex_acts[(num_sex_acts['Age_group'] == current_age)].Female_Lower.values\n",
    "            \n",
    "            number_of_sex_acts_risk_age[risk,age_index] = lower+((upper-lower)/sex_act_calibration_param[risk])\n",
    "    \n",
    "    \n",
    "    \"\"\"###\"\"\"        \n",
    "    condom_efficiency = pd.read_excel(excel, sheet_name='condom_efficiency').values\n",
    "    \n",
    "    \"\"\"###\"\"\"\n",
    "    prop_anal_acts = np.zeros((num_risk_groups, num_age_groups))\n",
    "    prop_acts_pd = pd.read_excel(excel, sheet_name='prop_anal_acts')\n",
    "    for risk in range(num_risk_groups):\n",
    "        current_risk = risk_groups[risk]\n",
    "        prop_anal_acts[risk] = prop_acts_pd[current_risk].values\n",
    "    \n",
    "    #print(prop_anal_acts, prop_anal_acts.shape)\n",
    "    \"\"\"###\"\"\"\n",
    "    \n",
    "    prop_casual_partner_v = pd.read_excel(excel, sheet_name='prop_casual_partner') \n",
    "    prop_casual_partner_risk = np.zeros((num_risk_groups, 2)) #columns [0]prob_casual\t[1]prob_casual_only\n",
    "    \n",
    "    for risk in range(num_risk_groups):\n",
    "        current_risk_group = risk_groups[risk]\n",
    "        prop_casual_partner_risk[risk] = prop_casual_partner_v[(prop_casual_partner_v['Group'] == current_risk_group)].values[:,1:3]\n",
    "    \n",
    "    prop_casual_partner_risk_casual = prop_casual_partner_risk[:,0]\n",
    "    prop_casual_partner_risk_casual_only = prop_casual_partner_risk[:,1]\n",
    "    \n",
    "    \"\"\"###\"\"\"\n",
    "    num_partner = pd.read_excel(excel, sheet_name='num_partner')\n",
    "    num_partner_risk = np.zeros((num_risk_groups,2))\n",
    "    \n",
    "    for risk in range(num_risk_groups):\n",
    "        current_risk_group = risk_groups[risk]\n",
    "        num_partner_risk[risk] = num_partner[(num_partner['Group'] == current_risk_group)].values[:,1:3]\n",
    "    \n",
    "    num_partner_risk_casual_only = num_partner_risk[:,0]\n",
    "    num_partner_risk_casual = num_partner_risk[:,1]\n",
    "    \n",
    "    #print(num_partner_risk_casual, num_partner_risk_casual_only)\n",
    "    \n",
    "    \"\"\"###\"\"\"\n",
    "    num_cas_part_main_cas = pd.read_excel(excel, sheet_name ='num_cas_part_main-cas').values\n",
    "    \n",
    "    \"\"\"###\"\"\"\n",
    "    prop_condom_use = pd.read_excel(excel, sheet_name='prop_condom_use')\n",
    "    prop_condom_use_risk_age_casual = np.zeros((num_risk_groups, num_age_groups))\n",
    "    prop_condom_use_risk_age_main = np.zeros((num_risk_groups, num_age_groups))\n",
    "    \n",
    "    \n",
    "    prop_condom_use_risk_age_main[0] = prop_condom_use.values[:,3]\n",
    "    prop_condom_use_risk_age_main[1] = prop_condom_use.values[:,1]\n",
    "    prop_condom_use_risk_age_main[2] = prop_condom_use.values[:,5]\n",
    "    \n",
    "    prop_condom_use_risk_age_casual[0] = prop_condom_use.values[:,4]\n",
    "    prop_condom_use_risk_age_casual[1] = prop_condom_use.values[:,2]\n",
    "    prop_condom_use_risk_age_casual[2] = prop_condom_use.values[:,6]\n",
    "    \n",
    "    \"\"\"###\"\"\"    \n",
    "    trans_prob = pd.read_excel(excel, sheet_name='trans_prob')\n",
    "    trans_prob_v_acts = np.zeros((num_risk_groups))\n",
    "    trans_prob_a_acts = np.zeros((num_risk_groups))\n",
    "    \n",
    "    for risk in range(num_risk_groups):\n",
    "        current_risk_group = risk_groups[risk]\n",
    "        trans_prob_v_acts[risk] = trans_prob[(trans_prob['Group'] == current_risk_group)].vaginal.values\n",
    "        trans_prob_a_acts[risk] = trans_prob[(trans_prob['Group'] == current_risk_group)].anal.values\n",
    "        \n",
    "    #print(trans_prob_v_acts, trans_prob_a_acts)\n",
    "    \n",
    "    \"\"\"###\"\"\" \n",
    "    sex_mixing = pd.read_excel(excel, sheet_name='sex_mixing').values\n",
    "    \n",
    "    \"\"\"###\"\"\" \n",
    "    #excel = 'input_estimating_unknown_rates_PATH.xlsx'\n",
    "    excel = 'input_estimating_unknown_rates_HOPE.xlsx'\n",
    "    testing_mult_fac = pd.read_excel(excel, sheet_name = 'testing_mult_fac')\n",
    "    testing_mult_fac_risk = np.zeros((num_risk_groups,5))\n",
    "    \n",
    "    for risk in range(num_risk_groups):\n",
    "        current_risk_group = risk_groups[risk]\n",
    "        testing_mult_fac_risk[risk] = testing_mult_fac[current_risk_group]\n",
    "        \n",
    "        \n",
    "    \"\"\"###\"\"\"\n",
    "    excel = 'input_new_infections.xlsx'\n",
    "    age_mixing_diag = pd.read_excel(excel, sheet_name = 'age_mix_diagonals')\n",
    "    #print(age_mixing_diag.values[0])\n",
    "    #print(num_cas_part_main_cas)\n",
    "    new_infections_data = {\n",
    "        \"q\": q,\n",
    "        \"age_mixing_final_mat\": age_mixing_final_mat,\n",
    "        \"pi\": pi,\n",
    "        \"number_of_sex_acts_risk_age\": number_of_sex_acts_risk_age,\n",
    "        \"condom_efficiency\": condom_efficiency,\n",
    "        \"prop_anal_acts\": prop_anal_acts,\n",
    "        \"prop_casual_partner_risk_casual\": prop_casual_partner_risk_casual,\n",
    "        \"prop_casual_partner_risk_casual_only\": prop_casual_partner_risk_casual_only,\n",
    "        \"num_partner_risk_casual\": num_partner_risk_casual,\n",
    "        \"num_partner_risk_casual_only\": num_partner_risk_casual_only,\n",
    "        \"num_cas_part_main_cas\": num_cas_part_main_cas,\n",
    "        \"prop_condom_use_risk_age_main\": prop_condom_use_risk_age_main,\n",
    "        \"prop_condom_use_risk_age_casual\": prop_condom_use_risk_age_casual,\n",
    "        \"trans_prob_v_acts\": trans_prob_v_acts,\n",
    "        \"trans_prob_a_acts\": trans_prob_a_acts,\n",
    "        \"sex_mixing\": sex_mixing,\n",
    "        \"testing_mult_fac_risk\": testing_mult_fac_risk,\n",
    "        \"age_mixing_diagonals\": age_mixing_diag}\n",
    "    \n",
    "    return(new_infections_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_death_rates(age_begin, age_end, risk_groups):\n",
    "    \n",
    "    num_risk_groups = len(risk_groups)\n",
    "    num_age_groups = age_end-age_begin+1\n",
    "    \n",
    "    #excel = 'input_estimating_unknown_rates_PATH.xlsx'\n",
    "    #excel = 'input_estimating_unknown_rates_HOPE.xlsx'\n",
    "    excel = 'input_estimating_unknown_rates_MOD_v2.xlsx'\n",
    "    \n",
    "    \"\"\"death_rate_uninf = pd.read_excel(excel, sheet_name = 'death_prob_uninf')\n",
    "    death_rate_inf = pd.read_excel(excel, sheet_name = 'death_prob_inf')\n",
    "    death_rate_a200 = pd.read_excel(excel, sheet_name = 'death_prob_a200')\n",
    "    death_rate_b200 = pd.read_excel(excel, sheet_name = 'death_prob_b200')\n",
    "    \n",
    "    death_rate_uninf_risk_age = np.zeros((num_risk_groups, num_age_groups))\n",
    "    for risk in range(num_risk_groups):\n",
    "        current_risk_group = risk_groups[risk]\n",
    "        \n",
    "        death_rate_uninf_risk_age[risk] = death_rate_uninf[current_risk_group].values\n",
    "    \n",
    "    death_rate_inf_v = death_rate_inf.values  \n",
    "    death_rate_a200_age_2010 = death_rate_a200[2010].values\n",
    "    death_rate_a200_age_2016 = death_rate_a200[2016].values\n",
    "    death_rate_b200_age_2010 = death_rate_b200[2010].values\n",
    "    death_rate_b200_age_2016 = death_rate_b200[2016].values\n",
    "    \n",
    "    \n",
    "    death_rate_inf_no_ART_acute = 0\n",
    "    death_rate_inf_no_ART_above_500 = 0\n",
    "    death_rate_inf_no_ART_above_350_500 = 0\n",
    "    death_rate_inf_no_ART_below_200 = 0\n",
    "    death_rate_inf_ART_below_200_age = 0\n",
    "    death_rate_inf_ART_200_350_age = 0\n",
    "    death_rate_inf_ART_above_350 = 0\n",
    "    \"\"\"\n",
    "    death_rate_a200_age_2010 = 0    \n",
    "    death_rate_a200_age_2016 = 0\n",
    "    death_rate_b200_age_2010 = 0\n",
    "    death_rate_b200_age_2016 = 0\n",
    "    death_rate_inf_v = 0\n",
    "    \n",
    "    #The following lines of code are used if I used MOD dataset\n",
    "    death_rate_uninf = pd.read_excel(excel, sheet_name = 'death_prob_uninf')\n",
    "    death_rate_inf_no_art = pd.read_excel(excel, sheet_name = 'death_prob_inf_no_art')\n",
    "    death_prob_inf_art = pd.read_excel(excel, sheet_name = 'death_prob_inf_art')\n",
    "    \n",
    "    death_rate_uninf_risk_age = np.zeros((num_risk_groups, num_age_groups))\n",
    "    for risk in range(num_risk_groups):\n",
    "        current_risk_group = risk_groups[risk]\n",
    "        \n",
    "        death_rate_uninf_risk_age[risk] = death_rate_uninf[current_risk_group].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    death_rate_inf_no_ART_acute = death_rate_inf_no_art[(death_rate_inf_no_art['CD4_category'] == \"Acute\")][\"death_rate\"].values\n",
    "    death_rate_inf_no_ART_above_500 = death_rate_inf_no_art[(death_rate_inf_no_art['CD4_category'] == \"CD4 >500\")][\"death_rate\"].values\n",
    "    death_rate_inf_no_ART_above_350_500 = death_rate_inf_no_art[(death_rate_inf_no_art['CD4_category'] == \"CD4 350-500\")][\"death_rate\"].values\n",
    "    death_rate_inf_no_ART_above_200_350 = death_rate_inf_no_art[(death_rate_inf_no_art['CD4_category'] == \"CD4 200-350\")][\"death_rate\"].values\n",
    "    death_rate_inf_no_ART_below_200 = death_rate_inf_no_art[(death_rate_inf_no_art['CD4_category'] == \"CD4 <200\")][\"death_rate\"].values\n",
    "    \n",
    "    death_rate_inf_ART_below_200_age = death_prob_inf_art[\"CD4_b_200\"].values\n",
    "    death_rate_inf_ART_200_350_age = death_prob_inf_art[\"CD4_200_350\"].values\n",
    "    death_rate_inf_ART_above_350_age = death_prob_inf_art[\"CD4_a_350\"].values\n",
    "    \n",
    "    death_prob_data = {\n",
    "        \"death_rate_uninf_risk_age\": death_rate_uninf_risk_age,\n",
    "        \"death_rate_inf\": death_rate_inf_v,\n",
    "        \"death_rate_a200_age_2010\": death_rate_a200_age_2010,\n",
    "        \"death_rate_a200_age_2016\": death_rate_a200_age_2016,\n",
    "        \"death_rate_b200_age_2010\": death_rate_b200_age_2010,\n",
    "        \"death_rate_b200_age_2016\": death_rate_b200_age_2016,\n",
    "        \"death_rate_inf_no_ART_acute\": death_rate_inf_no_ART_acute,\n",
    "        \"death_rate_inf_no_ART_above_500\": death_rate_inf_no_ART_above_500,\n",
    "        \"death_rate_inf_no_ART_above_350_500\": death_rate_inf_no_ART_above_350_500,\n",
    "        \"death_rate_inf_no_ART_above_200_350\": death_rate_inf_no_ART_above_200_350,\n",
    "        \"death_rate_inf_no_ART_below_200\": death_rate_inf_no_ART_below_200,\n",
    "        \"death_rate_inf_ART_below_200_age\": death_rate_inf_ART_below_200_age,\n",
    "        \"death_rate_inf_ART_200_350_age\": death_rate_inf_ART_200_350_age,\n",
    "        \"death_rate_inf_ART_above_350_age\": death_rate_inf_ART_above_350_age}\n",
    "    \n",
    "    \n",
    "    #print(death_prob_data)\n",
    "    \n",
    "    #print(death_prob_data[\"death_rate_uninf_risk_age\"].shape, death_prob_data[\"death_rate_uninf_risk_age\"])\n",
    "    \n",
    "    return(death_prob_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deaths_vector(number_of_compartments, \n",
    "                            risk_groups, \n",
    "                            group, \n",
    "                            age, \n",
    "                            death_prob_data):\n",
    "    \n",
    "    current_age = age+13\n",
    "    current_risk_group = risk_groups[group]\n",
    "    #print(death_prob_data[\"death_rate_uninf_risk_age\"].shape)\n",
    "    \"\"\"print(\"Group = \", current_risk_group)\n",
    "    print(\"Age = \",current_age)\n",
    "    print(\"year_to_simulate =\", year_to_simulate)\"\"\"\n",
    "    \"\"\" Need to multiply this with dt to get monthly rates if simulation time interval is monthly\"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    death_col_annual = np.zeros((number_of_compartments,1))\n",
    "    death_col_annual[0,:] = death_prob_data[\"death_rate_uninf_risk_age\"][group,age].copy()\n",
    "    \n",
    "    #ART_more_200 = np.arange(1,18)\n",
    "    #no_ART_less_200 = (17,18)\n",
    "    #ART_less_200 = (19,20)\n",
    "    \n",
    "    ART_more_200 = np.array([3,4,7,8,11,12,15,16])\n",
    "    no_ART = np.array([1,2,5,6,9,10,13,14,17,18])\n",
    "    ART_less_200 = np.array([19,20])\n",
    "    \n",
    "    \n",
    "    if(year_to_simulate < 2016):\n",
    "        \n",
    "        death_rate_after_200 = death_prob_data[\"death_rate_a200_age_2010\"][age].copy()\n",
    "        death_rate_before_200 = death_prob_data[\"death_rate_b200_age_2010\"][age].copy()\n",
    "    \n",
    "    elif(year_to_simulate >= 2016):\n",
    "        \n",
    "        death_rate_after_200 = death_prob_data[\"death_rate_a200_age_2016\"][age].copy()\n",
    "        death_rate_before_200 = death_prob_data[\"death_rate_b200_age_2016\"][age].copy()\n",
    "    #print(\"death_prob_data\",death_prob_data[\"death_rate_inf\"][0,0].copy())\n",
    "    \n",
    "    death_col_annual[ART_more_200,:] = np.repeat(death_rate_after_200, len(ART_more_200)).reshape(len(ART_more_200),1)\n",
    "    death_col_annual[no_ART,:] = np.repeat(death_prob_data[\"death_rate_inf\"][0,0].copy(), len(no_ART)).reshape(len(no_ART),1)\n",
    "    death_col_annual[ART_less_200,:] = np.repeat(death_rate_before_200, len(ART_less_200)).reshape(len(ART_less_200),1)        \n",
    "    death_col_annual[21,:] = 0\n",
    "    \"\"\"\n",
    "    \n",
    "    # MODIFIED rates (include CD4 specific values)\n",
    "    \n",
    "    death_col_annual = np.zeros((number_of_compartments,1))\n",
    "    death_col_annual[0,:] = death_prob_data[\"death_rate_uninf_risk_age\"][group,age].copy()\n",
    "    \n",
    "    #print(death_prob_data[\"death_rate_inf_no_ART_acute\"])\n",
    "    death_col_annual[1,:] = death_prob_data[\"death_rate_inf_no_ART_acute\"].copy()\n",
    "    death_col_annual[2,:] = death_prob_data[\"death_rate_inf_no_ART_acute\"].copy()\n",
    "    death_col_annual[3,:] = death_prob_data[\"death_rate_inf_ART_above_350_age\"][age].copy()\n",
    "    death_col_annual[4,:] = death_prob_data[\"death_rate_inf_ART_above_350_age\"][age].copy()\n",
    "    \n",
    "    death_col_annual[5,:] = death_prob_data[\"death_rate_inf_no_ART_above_500\"].copy()\n",
    "    death_col_annual[6,:] = death_prob_data[\"death_rate_inf_no_ART_above_500\"].copy()\n",
    "    death_col_annual[7,:] = death_prob_data[\"death_rate_inf_ART_above_350_age\"][age].copy()\n",
    "    death_col_annual[8,:] = death_prob_data[\"death_rate_inf_ART_above_350_age\"][age].copy()  \n",
    "    \n",
    "    death_col_annual[9,:] = death_prob_data[\"death_rate_inf_no_ART_above_350_500\"].copy()\n",
    "    death_col_annual[10,:] = death_prob_data[\"death_rate_inf_no_ART_above_350_500\"].copy()\n",
    "    death_col_annual[11,:] = death_prob_data[\"death_rate_inf_ART_above_350_age\"][age].copy()\n",
    "    death_col_annual[12,:] = death_prob_data[\"death_rate_inf_ART_above_350_age\"][age].copy()\n",
    "    \n",
    "    death_col_annual[13,:] = death_prob_data[\"death_rate_inf_no_ART_above_200_350\"].copy()\n",
    "    death_col_annual[14,:] = death_prob_data[\"death_rate_inf_no_ART_above_200_350\"].copy()\n",
    "    death_col_annual[15,:] = death_prob_data[\"death_rate_inf_ART_200_350_age\"][age].copy()\n",
    "    death_col_annual[16,:] = death_prob_data[\"death_rate_inf_ART_200_350_age\"][age].copy()\n",
    "    \n",
    "    death_col_annual[17,:] = death_prob_data[\"death_rate_inf_no_ART_below_200\"].copy()\n",
    "    death_col_annual[18,:] = death_prob_data[\"death_rate_inf_no_ART_below_200\"].copy()\n",
    "    death_col_annual[19,:] = death_prob_data[\"death_rate_inf_ART_below_200_age\"][age].copy()\n",
    "    death_col_annual[20,:] = death_prob_data[\"death_rate_inf_ART_below_200_age\"][age].copy()\n",
    "    \n",
    "    death_col_annual[21,:] = 0\n",
    "        \n",
    "    #print(1-death_col_annual)\n",
    "    death_col_log = (-np.log(1-death_col_annual)) #*(1-0.56)#*(1-0.4543948)\n",
    "    #print(\"group=\",group,\"age=\",age,\"\\n\")\n",
    "    #print(np.sum(death_col_log))\n",
    "    #print(death_col_log)\n",
    "    \"\"\"if(group == 0):\n",
    "        if(age == 0):\n",
    "            print(death_col_log)\"\"\"\n",
    "    return(death_col_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195dc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltc_prep_values(ltc_excel, jur_list):\n",
    "    \n",
    "    df_hm_ltc = pd.read_excel(ltc_excel, sheet_name='jur_specific_care_cont_hm')\n",
    "    df_hf_ltc = pd.read_excel(ltc_excel, sheet_name='jur_specific_care_cont_hf')\n",
    "    df_msm_ltc = pd.read_excel(ltc_excel, sheet_name='jur_specific_care_cont_msm')\n",
    "    \n",
    "    ltc_risk = np.zeros((len(jur_list), number_of_risk_groups))\n",
    "    \n",
    "    for loc in range(len(jur_list)):\n",
    "        d_hm = df_hm_ltc[df_hm_ltc['FIPS']==jur_list[loc]]\n",
    "        d_hf = df_hf_ltc[df_hf_ltc['FIPS']==jur_list[loc]]\n",
    "        d_msm = df_msm_ltc[df_msm_ltc['FIPS']==jur_list[loc]]\n",
    "\n",
    "        ltc_vals = np.array([d_hm.LTC.values[0],\n",
    "                             d_hf.LTC.values[0],\n",
    "                             d_msm.LTC.values[0]])\n",
    "        \n",
    "        ltc_risk[loc] = ltc_vals\n",
    "    \n",
    "    return ltc_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_x1_y1_value(new_infections_data):\n",
    "    \n",
    "    condom_awareness = np.array([0,0.53,0.53,0.53])\n",
    "    prob_condom_efficency = new_infections_data[\"condom_efficiency\"][0,0].copy()\n",
    "\n",
    "    c = np.tile(condom_awareness,5).reshape(number_of_compartments-2)\n",
    "    \n",
    "    pi_v = new_infections_data[\"pi\"].reshape((number_of_compartments-2)).copy()\n",
    "\n",
    "    pi = pi_v[np.newaxis,:]\n",
    "    p_v_x1 = new_infections_data[\"trans_prob_v_acts\"].copy()[:,np.newaxis]\n",
    "    p_a_x1 = new_infections_data[\"trans_prob_a_acts\"].copy()[:,np.newaxis]\n",
    "\n",
    "    p_bar_v_x1 = (1-prob_condom_efficency)*p_v_x1\n",
    "    p_bar_a_x1 = (1-prob_condom_efficency)*p_a_x1\n",
    "    \n",
    "    num_sex_acts = new_infections_data[\"number_of_sex_acts_risk_age\"].copy()\n",
    "    prob_anal_acts = new_infections_data[\"prop_anal_acts\"].copy()\n",
    "    n_v_x1_y1 = num_sex_acts*(1-prob_anal_acts)\n",
    "    n_a_x1_y1 = num_sex_acts*prob_anal_acts\n",
    "    \n",
    "    num_cas_part_main_cas = new_infections_data[\"num_cas_part_main_cas\"].copy()[0:num_risk]\n",
    "    nc = (num_cas_part_main_cas*2)/(num_sex_acts)\n",
    "    nm = 1-nc\n",
    "    \n",
    "    prob_casual_only = new_infections_data[\"prop_casual_partner_risk_casual_only\"].copy()[:,np.newaxis]\n",
    "    prob_casual = new_infections_data[\"prop_casual_partner_risk_casual\"].copy()[:,np.newaxis]\n",
    "\n",
    "    prob_condom_casual = new_infections_data[\"prop_condom_use_risk_age_casual\"].copy()\n",
    "    prob_condom_main = new_infections_data[\"prop_condom_use_risk_age_main\"].copy()\n",
    "\n",
    "    prop_condom_use_calc = ((prob_casual_only*prob_condom_casual)+                                     #only casual\n",
    "                                        (abs(prob_casual-prob_casual_only)*prob_condom_casual*nc)+ #casual among casual-main\n",
    "                                        (abs(prob_casual-prob_casual_only)*prob_condom_main*nm)+     #main among casual-main\n",
    "                                        ((1-prob_casual)*prob_condom_main)) \n",
    "    \n",
    "    num_partners_tot = new_infections_data[\"num_partner_risk_casual\"].copy() + \\\n",
    "                        new_infections_data[\"num_partner_risk_casual_only\"].copy()\n",
    "    \n",
    "    lower1 = (1-(p_bar_v_x1*pi))[:,np.newaxis,:]\n",
    "\n",
    "    upper1 = ((n_v_x1_y1*dt)[:,:,np.newaxis]*(((1-prop_condom_use_calc)[:,:,np.newaxis]*c[np.newaxis,np.newaxis,:])+\n",
    "                                             prop_condom_use_calc[:,:,np.newaxis]))/(num_partners_tot*dt)[:,np.newaxis,np.newaxis]\n",
    "\n",
    "    AA = lower1**upper1\n",
    "    \n",
    "    lower2 = (1-(p_v_x1*pi))[:,np.newaxis,:]\n",
    "\n",
    "    upper2 = ((n_v_x1_y1*dt)[:,:,np.newaxis]*(1-prop_condom_use_calc)[:,:,np.newaxis]*(1-c[np.newaxis,np.newaxis,:]))/  \\\n",
    "                                            (num_partners_tot*dt)[:,np.newaxis,np.newaxis]\n",
    "\n",
    "    BB = lower2**upper2\n",
    "    \n",
    "    lower3 = (1-(p_bar_a_x1*pi))[:,np.newaxis,:]\n",
    "\n",
    "    upper3 = ((n_a_x1_y1*dt)[:,:,np.newaxis]*(((1-prop_condom_use_calc)[:,:,np.newaxis]*c[np.newaxis,np.newaxis,:])+\n",
    "                                              prop_condom_use_calc[:,:,np.newaxis]))/(num_partners_tot*dt)[:,np.newaxis,np.newaxis]\n",
    "\n",
    "    CC = lower3**upper3\n",
    "    \n",
    "    lower4 = (1-(p_a_x1*pi))[:,np.newaxis,:]\n",
    "\n",
    "    upper4 = ((n_a_x1_y1*dt)[:,:,np.newaxis]*(1-prop_condom_use_calc)[:,:,np.newaxis]*(1-c[np.newaxis,np.newaxis,:]))/  \\\n",
    "                                            (num_partners_tot*dt)[:,np.newaxis,np.newaxis]\n",
    "\n",
    "    DD = lower4**upper4\n",
    "    \n",
    "    M_x1_y1_i = 1-(1-(AA*BB*CC*DD))\n",
    "    \n",
    "    return M_x1_y1_i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_infections_per_month(num_jur, data_array, new_infections_data, M_x1_y1_i, prep_risk):\n",
    "    \n",
    "    risk_mat = new_infections_data[\"sex_mixing\"].copy()[0:num_risk,0:num_risk]\n",
    "    age_mat = new_infections_data[\"age_mixing_final_mat\"].copy()\n",
    "    \n",
    "    I = data_array[:,:,:,1:21]\n",
    "    N = np.sum(data_array[:,:,:,0:21], axis=3)\n",
    "    d_x1_y1 = new_infections_data[\"num_partner_risk_casual\"].copy()+new_infections_data[\"num_partner_risk_casual_only\"].copy()\n",
    "    sus_x1_y1 = data_array[:,:,:,0]\n",
    "    mat_vector = np.repeat(age_mat[:,np.newaxis,:,:],num_risk, axis = 1) * risk_mat[:,:,np.newaxis, np.newaxis]\n",
    "    I_N_vector = I / N[:,:,:,np.newaxis]\n",
    "    I_N_mult_vector = mat_vector[np.newaxis,:,:,:,:,np.newaxis]*I_N_vector[:,np.newaxis,:,np.newaxis,:,:]\n",
    "    Q_inner_vector = np.apply_over_axes(np.sum, I_N_mult_vector, [2,4]).reshape((num_jur, num_risk,num_age,num_comp))\n",
    "    q_x_y_i_vector = d_x1_y1[np.newaxis,:,np.newaxis,np.newaxis]*dt*Q_inner_vector\n",
    "    q_mix_vector = np.zeros((num_jur,num_jur,num_risk,num_age,num_comp))\n",
    "    for risk in range(num_risk):\n",
    "        q_mix_vector[:,:,risk,:,:] = mixing_matrix[risk][:,:,np.newaxis,np.newaxis]*q_x_y_i_vector[:,risk,:,:][np.newaxis,:,:,:]\n",
    "    q_mix_sum_vector = np.sum(q_mix_vector, axis = 1)\n",
    "    M_power_vector = M_x1_y1_i[np.newaxis,:,:,:]**q_mix_sum_vector\n",
    "    M_prod_vector = 1-np.prod(M_power_vector, axis = 3) \n",
    "    \n",
    "    new_inf_per_month = sus_x1_y1*(1 - prep_risk[:,:,np.newaxis])*M_prod_vector\n",
    "    \n",
    "    return new_inf_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proportions(data_array, num_jur, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index,VLS_index):\n",
    "    \n",
    "    plwh_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    unaware_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    aware_no_art_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    aware_art_vls_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    vls_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    \n",
    "    for risk in range(number_of_risk_groups):\n",
    "        plwh_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,1:21], [1,2]).reshape(num_jur,)\n",
    "        unaware_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,unaware_index], [0,2]).reshape(num_jur,)\n",
    "        aware_no_art_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,aware_no_care_index], [0,2]).reshape(num_jur,)\n",
    "        aware_art_vls_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,ART_VLS_index], [0,2]).reshape(num_jur,)\n",
    "        vls_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,VLS_index], [0,2]).reshape(num_jur,)\n",
    "        \n",
    "    \n",
    "    total_pop = np.apply_over_axes(np.sum, data_array[:,:,:,0:21], [1,2,3]).reshape(num_jur,1)\n",
    "    \n",
    "    prevalence_prop = plwh_risk/total_pop\n",
    "    \n",
    "    unaware_prop = unaware_risk/plwh_risk\n",
    "    aware_no_art_prop = aware_no_art_risk/plwh_risk\n",
    "    aware_art_vls_prop = aware_art_vls_risk/plwh_risk\n",
    "    vls_prop = vls_risk/plwh_risk\n",
    "    \n",
    "    return total_pop, np.round(prevalence_prop, 6), np.round(unaware_prop, 6), \\\n",
    "                np.round(aware_no_art_prop, 6), np.round(aware_art_vls_prop, 6), vls_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881798f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnosis_rate(data_array, num_jur, a_unaware, unaware_index, number_of_risk_groups, new_inf_per_month, unaware_prop, death_per_month_risk_age_compartments):\n",
    "    \n",
    "    diagnosis_rate_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    \n",
    "    a_unaware_t = np.round(a_unaware*dt, 6)\n",
    "\n",
    "    for risk in range(len(risk_groups)):\n",
    "        # new infectiion per month\n",
    "        A = np.sum(new_inf_per_month, axis=2)[:,risk]\n",
    "\n",
    "        # number of unaware population\n",
    "        B = np.apply_over_axes(np.sum, data_array[:,risk,:,unaware_index], [0,2]).reshape(num_jur,)\n",
    "\n",
    "        #number of unaware next time period\n",
    "        # (current inf + new inf - total death)\n",
    "        C = (np.apply_over_axes(np.sum, data_array[:,risk,:,1:21], [1,2]).reshape(num_jur,) + A - np.apply_over_axes(np.sum, death_per_month_risk_age_compartments[:,risk,:,1:21],[1,2]).reshape(num_jur,)) * (unaware_prop[:,risk] + a_unaware_t[:,risk])\n",
    "\n",
    "        # total deaths in each compartment\n",
    "        D = np.apply_over_axes(np.sum, death_per_month_risk_age_compartments[:,risk,:,unaware_index],[0,2]).reshape(num_jur,)\n",
    "\n",
    "        # number of people in unaware compartment\n",
    "        E = np.sum(np.sum(data_array[:,risk,:, unaware_index],axis=2)*new_infections_data[\"testing_mult_fac_risk\"][risk].reshape(5,1), axis=0)\n",
    "        \n",
    "        diagnosis_rate_risk[:,risk] = (A+B-C-D)/E\n",
    "        \n",
    "        diagnosis_rate_risk[:,risk][diagnosis_rate_risk[:,risk] < 0] = 0\n",
    "        \n",
    "    return diagnosis_rate_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab914c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_rate(num_jur, a_art, ART_VLS_index, diagnosis_rate_risk, ltc_risk, gamma, number_of_risk_groups, data_array, new_inf_per_month, unaware_prop, aware_no_art_prop, aware_art_vls_prop, death_per_month_risk_age_compartments):\n",
    "    \n",
    "    dropout_rate_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    \n",
    "    a_art_t = np.round(a_art *dt, 6)\n",
    "    gamma_t = np.round(gamma *dt, 6)\n",
    "    \n",
    "    for risk in range(len(risk_groups)):\n",
    "       # total art vls pop \n",
    "        F = np.apply_over_axes(np.sum, data_array[:,risk,:,ART_VLS_index], [0,2]).reshape(num_jur,)\n",
    "        #multiply F with phi for denominator\n",
    "        \n",
    "        K = np.sum(np.sum(data_array[:,risk,:,ART_VLS_index], axis=2)*scaling_factor_dropout[risk].reshape(10,1), axis=0)        \n",
    "        # diagnosed and linked to care\n",
    "        \n",
    "        G = diagnosis_rate_risk[:,risk]*ltc_risk[:,risk]*np.sum((np.sum(data_array[:,risk,:,unaware_index],axis=2))*new_infections_data[\"testing_mult_fac_risk\"][risk].reshape(5,1), axis=0)\n",
    "\n",
    "        #entering care from unaware\n",
    "        H = np.sum(gamma_t[risk].reshape(5,1)*np.sum(data_array[:,risk,:,aware_no_care_index], axis=2), axis=0)\n",
    "\n",
    "        #total death art vls\n",
    "        I = np.apply_over_axes(np.sum,death_per_month_risk_age_compartments[:,risk,:,ART_VLS_index],[0,2]).reshape(num_jur,)\n",
    "\n",
    "        #number of art vls next time period\n",
    "        J = (np.apply_over_axes(np.sum, data_array[:,risk,:,1:21], [1,2]).reshape(num_jur,) + np.sum(new_inf_per_month, axis=2)[:,risk] - np.apply_over_axes(np.sum, death_per_month_risk_age_compartments[:,risk,:,1:21],[1,2]).reshape(num_jur,)) * (aware_art_vls_prop[:,risk] + a_art_t[:,risk])\n",
    "        \n",
    "        dropout_rate_risk[:,risk] = (F+G+H-I-J)/K\n",
    "        \n",
    "#         if dropout_rate_risk[:,risk].any() < 0:\n",
    "        dropout_rate_risk[:,risk][dropout_rate_risk[:,risk] < 0] = 0\n",
    "        \n",
    "    return dropout_rate_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_matrix(num_jur, new_infections_data, diagnosis_rate_risk, dropout_rate_risk, ltc_risk):\n",
    "    \n",
    "    Q_MAT = new_infections_data['q']\n",
    "    Q_matrix = np.zeros((num_jur, number_of_risk_groups, number_of_compartments, number_of_compartments))\n",
    "    \n",
    "    for jur in range(num_jur):\n",
    "        for risk in range(number_of_risk_groups):\n",
    "            Q_mat = Q_MAT.copy()\n",
    "            Q_mat[np.where(Q_mat == 12345)] = (1 - ltc_risk[jur,risk]) * diagnosis_rate_risk[jur,risk]*new_infections_data[\"testing_mult_fac_risk\"][risk]\n",
    "            Q_mat[np.where(Q_mat == 123456)] = dropout_rate_risk[jur,risk]\n",
    "            Q_mat[np.where(Q_mat == 1234567)] = ltc_risk[jur,risk] * diagnosis_rate_risk[jur,risk]*new_infections_data[\"testing_mult_fac_risk\"][risk]\n",
    "\n",
    "            Q_matrix[jur,risk] = Q_mat\n",
    "            \n",
    "        \n",
    "    return Q_matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a180b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_mat_diag(Q_matrix, num_jur):\n",
    "    \n",
    "    Q_matrix_diagonal = np.zeros((num_jur, number_of_risk_groups, number_of_compartments, number_of_compartments))\n",
    "    \n",
    "    for jur in range(num_jur):\n",
    "        for risk in range(number_of_risk_groups):\n",
    "            Q_i = Q_matrix[jur,risk].copy()\n",
    "            Q_i_sum = np.sum(Q_i, 1)\n",
    "            Q_matrix_diagonal[jur,risk] = np.diag(Q_i_sum)\n",
    "        \n",
    "    return Q_matrix_diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aging(data_array, pop_susceptible_12_years):\n",
    "    new_pop = np.zeros((num_jur, number_of_risk_groups, num_age, number_of_compartments))\n",
    "    \n",
    "    new_pop[:,:,1:,:] = data_array[:,:,0:num_age-1,:]\n",
    "    new_pop[:,:,0,0] = pop_susceptible_12_years\n",
    "    \n",
    "    return new_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd50f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc_excel ='CareContinuum-by_jur 7-26-2021 HT V2.xlsx'\n",
    "\n",
    "ltc_risk = ltc_prep_values(ltc_excel, all_jurisdictions)  # linked to care rate\n",
    "\n",
    "new_infections_data = read_new_inf_input(age_begin, age_end, risk_groups) # new infection data from excel\n",
    "\n",
    "M_x1_y1_i = M_x1_y1_value(new_infections_data)\n",
    "\n",
    "death_prob_data = read_death_rates(age_begin, age_end, risk_groups)\n",
    "\n",
    "death_rate_risk_age_compartments = np.zeros((num_jur, number_of_risk_groups, age_groups, number_of_compartments))\n",
    "\n",
    "for risk in range(len(risk_groups)):\n",
    "    for age in range(age_groups):\n",
    "        death_rate_risk_age_compartments[:,risk,age,] = calculate_deaths_vector(number_of_compartments, risk_groups, risk, age, death_prob_data).reshape(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3384c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state(data_array, prep_values):\n",
    "    \n",
    "    data_array_cluster1 = data_array[cluster1_index,:,:,:]\n",
    "    data_array_cluster2 = data_array[cluster2_index,:,:,:]\n",
    "    data_array_cluster3 = data_array[cluster3_index,:,:,:]\n",
    "    data_array_cluster4 = data_array[cluster4_index,:,:,:]\n",
    "    data_array_cluster5 = data_array[cluster5_index,:,:,:]\n",
    "    data_array_cluster6 = data_array[cluster6_index,:,:,:]\n",
    "    data_array_cluster7 = data_array[cluster7_index,:,:,:]\n",
    "    data_array_cluster8 = data_array[cluster8_index,:,:,:]\n",
    "    \n",
    "    #prep_rate\n",
    "    total_data_cluster1 = np.sum(data_array_cluster1, axis=0)\n",
    "    total_data_cluster1 = total_data_cluster1[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster2 = np.sum(data_array_cluster2, axis=0)\n",
    "    total_data_cluster2 = total_data_cluster2[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster3 = np.sum(data_array_cluster3, axis=0)\n",
    "    total_data_cluster3 = total_data_cluster3[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster4 = np.sum(data_array_cluster4, axis=0)\n",
    "    total_data_cluster4 = total_data_cluster4[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster5 = np.sum(data_array_cluster5, axis=0)\n",
    "    total_data_cluster5 = total_data_cluster5[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster6 = np.sum(data_array_cluster6, axis=0)\n",
    "    total_data_cluster6 = total_data_cluster6[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster7 = np.sum(data_array_cluster7, axis=0)\n",
    "    total_data_cluster7 = total_data_cluster7[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster8 = np.sum(data_array_cluster8, axis=0)\n",
    "    total_data_cluster8 = total_data_cluster8[np.newaxis,:,:,:]\n",
    "\n",
    "    \n",
    "    total_pop1, prevalence_prop1, unaware_prop1, aware_no_art_prop1, aware_art_vls_prop1,_ = calculate_proportions(total_data_cluster1, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop2, prevalence_prop2, unaware_prop2, aware_no_art_prop2, aware_art_vls_prop2,_ = calculate_proportions(total_data_cluster2, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop3, prevalence_prop3, unaware_prop3, aware_no_art_prop3, aware_art_vls_prop3,_ = calculate_proportions(total_data_cluster3, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop4, prevalence_prop4, unaware_prop4, aware_no_art_prop4, aware_art_vls_prop4,_ = calculate_proportions(total_data_cluster4, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop5, prevalence_prop5, unaware_prop5, aware_no_art_prop5, aware_art_vls_prop5,_ = calculate_proportions(total_data_cluster5, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop6, prevalence_prop6, unaware_prop6, aware_no_art_prop6, aware_art_vls_prop6,_ = calculate_proportions(total_data_cluster6, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop7, prevalence_prop7, unaware_prop7, aware_no_art_prop7, aware_art_vls_prop7,_ = calculate_proportions(total_data_cluster7, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop8, prevalence_prop8, unaware_prop8, aware_no_art_prop8, aware_art_vls_prop8,_ = calculate_proportions(total_data_cluster8, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "\n",
    "    prep_coverage1 = data_array_cluster1[:,2,:,0]*prep_values[cluster1_index,2][:,np.newaxis]\n",
    "    prep1 = np.round(np.apply_over_axes(np.sum, prep_coverage1, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster1[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop1 = np.array([0,0,prep1])\n",
    "    \n",
    "    prep_coverage2 = data_array_cluster2[:,2,:,0]*prep_values[cluster2_index,2][:,np.newaxis]\n",
    "    prep2 = np.round(np.apply_over_axes(np.sum, prep_coverage2,[0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster2[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop2 = np.array([0,0,prep2])\n",
    "    \n",
    "    prep_coverage3= data_array_cluster3[:,2,:,0]*prep_values[cluster3_index,2][:,np.newaxis]\n",
    "    prep3= np.round(np.apply_over_axes(np.sum, prep_coverage3, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster3[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop3= np.array([0,0,prep3])\n",
    "    \n",
    "    prep_coverage4 = data_array_cluster4[:,2,:,0]*prep_values[cluster4_index,2][:,np.newaxis]\n",
    "    prep4 = np.round(np.apply_over_axes(np.sum, prep_coverage4, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster4[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop4 = np.array([0,0,prep4])\n",
    "    \n",
    "    prep_coverage5 = data_array_cluster5[:,2,:,0]*prep_values[cluster5_index,2][:,np.newaxis]\n",
    "    prep5 = np.round(np.apply_over_axes(np.sum, prep_coverage5,[0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster5[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop5 = np.array([0,0,prep5])\n",
    "    \n",
    "    prep_coverage6 = data_array_cluster6[:,2,:,0]*prep_values[cluster6_index,2][:,np.newaxis]\n",
    "    prep6= np.round(np.apply_over_axes(np.sum, prep_coverage6, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster6[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop6= np.array([0,0,prep6])\n",
    "    \n",
    "    prep_coverage7 = data_array_cluster7[:,2,:,0]*prep_values[cluster7_index,2][:,np.newaxis]\n",
    "    prep7 = np.round(np.apply_over_axes(np.sum, prep_coverage7, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster7[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop7 = np.array([0,0,prep7])\n",
    "    \n",
    "    prep_coverage8 = data_array_cluster8[:,2,:,0]*prep_values[cluster8_index,2][:,np.newaxis]\n",
    "    prep8 = np.round(np.apply_over_axes(np.sum, prep_coverage8,[0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster8[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop8 = np.array([0,0,prep8])\n",
    "    \n",
    "    \n",
    "    current_state1 = np.transpose(np.vstack((prevalence_prop1, unaware_prop1, aware_no_art_prop1, aware_art_vls_prop1, prep_prop1)))\n",
    "    current_state2 = np.transpose(np.vstack((prevalence_prop2, unaware_prop2, aware_no_art_prop2, aware_art_vls_prop2, prep_prop2)))\n",
    "    current_state3 = np.transpose(np.vstack((prevalence_prop3, unaware_prop3, aware_no_art_prop3, aware_art_vls_prop3, prep_prop3)))\n",
    "    current_state4 = np.transpose(np.vstack((prevalence_prop4, unaware_prop4, aware_no_art_prop4, aware_art_vls_prop4, prep_prop4)))\n",
    "    current_state5 = np.transpose(np.vstack((prevalence_prop5, unaware_prop5, aware_no_art_prop5, aware_art_vls_prop5, prep_prop5)))\n",
    "    current_state6 = np.transpose(np.vstack((prevalence_prop6, unaware_prop6, aware_no_art_prop6, aware_art_vls_prop6, prep_prop6)))\n",
    "    current_state7 = np.transpose(np.vstack((prevalence_prop7, unaware_prop7, aware_no_art_prop7, aware_art_vls_prop7, prep_prop7)))\n",
    "    current_state8 = np.transpose(np.vstack((prevalence_prop8, unaware_prop8, aware_no_art_prop8, aware_art_vls_prop8, prep_prop8)))\n",
    "    \n",
    "    return current_state1, current_state2, current_state3, current_state4, current_state5, current_state6, current_state7, current_state8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3374a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_data = data_array_cluster.copy()\n",
    "\n",
    "def initial_state(initial_data, prep_values):\n",
    "    state1,state2,state3,state4,state5,state6,state7,state8 = extract_state(initial_data, prep_values)\n",
    "    time = 0\n",
    "    return initial_data,state1,state2,state3,state4,state5,state6,state7,state8, prep_values, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd28406",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = initial_state(data_array_cluster, prep_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70020fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shi_value(I, N):\n",
    "    return (0.0153/0.0057)*(I/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b47bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.3\n",
    "tau = 0.3\n",
    "mu = 0.002\n",
    "alpha = 0.8\n",
    "\n",
    "c_r_n = 22.13\n",
    "c_c_n = 10.36\n",
    "n_n = 0.45\n",
    "c_add = 52.66\n",
    "\n",
    "c_r_p = 78.8\n",
    "c_c_p = 58.91\n",
    "n_r_p = 10.86\n",
    "n_c_p = 5.88\n",
    "c_cnf = 160.07\n",
    "\n",
    "O_v0 = 16.59\n",
    "W = 0.2 #[0.1,0.2,0.3]\n",
    "# del_x = #outreached people\n",
    "\n",
    "m_cl = 1000\n",
    "m_nc = 1000\n",
    "f_c = 56379\n",
    "f_nc = 64851\n",
    "\n",
    "m_o = 1000\n",
    "f_o = 50000\n",
    "\n",
    "R_art_0 = 235 #[117,235,300]\n",
    "Y = 0.2#[0.1,0.2,0.3]\n",
    "m_r = 500\n",
    "f_r = 22708 #[17977,22708,29330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I_t_0 = np.apply_over_axes(np.sum, data_array_cluster[:,:,:,1:21],[2,3]).reshape(num_jur, num_risk)\n",
    "# N_t_0 = np.apply_over_axes(np.sum, data_array_cluster[:,:,:,0:21],[2,3]).reshape(num_jur, num_risk)\n",
    "\n",
    "# x_t_a_0 = (delta_1*I_t_0*p_unaware_0 - mu*I_t_0*p_unaware_0) / (theta*shi_value(I_t_0,N_t_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9dacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t_a_0 = np.array([[2.33180375e+03, 3.63425551e+03, 3.04112649e+02],\n",
    "       [3.17936973e+04, 2.75670559e+04, 1.47418143e+03],\n",
    "       [1.36887484e+04, 1.30437095e+04, 5.32839478e+02],\n",
    "       [4.90237946e+03, 9.09907366e+03, 5.72640202e+02],\n",
    "       [1.47264430e+03, 3.48346071e+03, 3.16193026e+02],\n",
    "       [3.62561698e+03, 7.52180368e+03, 1.63632454e+02],\n",
    "       [5.32412773e+03, 1.15369335e+04, 4.73913288e+02],\n",
    "       [8.82399246e+02, 5.86348541e+02, 2.57480493e+02]])\n",
    "\n",
    "delta_1 = np.array([[0.0180713 , 0.03533054, 0.0314886 ],\n",
    "       [0.05123306, 0.059546  , 0.03496893],\n",
    "       [0.04669086, 0.05902862, 0.0339207 ],\n",
    "       [0.02449952, 0.0553693 , 0.03036947],\n",
    "       [0.01170278, 0.03310768, 0.03407533],\n",
    "       [0.01437995, 0.03664002, 0.01971395],\n",
    "       [0.01977946, 0.05301006, 0.02548554],\n",
    "       [0.038004  , 0.031486  , 0.06326625]])\n",
    "\n",
    "p_unaware_0 = np.array([[0.17989 , 0.12448 , 0.167303],\n",
    "       [0.132271, 0.090542, 0.123574],\n",
    "       [0.196625, 0.137524, 0.184114],\n",
    "       [0.196059, 0.138523, 0.185914],\n",
    "       [0.208705, 0.142397, 0.188764],\n",
    "       [0.282237, 0.20057 , 0.260866],\n",
    "       [0.186459, 0.130231, 0.174968],\n",
    "       [0.078656, 0.05356 , 0.074505]])\n",
    "\n",
    "p_art_0 = np.array([[0.565534, 0.647454, 0.627884],\n",
    "       [0.570325, 0.645897, 0.636072],\n",
    "       [0.536505, 0.620825, 0.599717],\n",
    "       [0.496017, 0.579814, 0.561497],\n",
    "       [0.646201, 0.72944 , 0.697714],\n",
    "       [0.543873, 0.639447, 0.6001  ],\n",
    "       [0.53376 , 0.616783, 0.597922],\n",
    "       [0.547729, 0.617069, 0.619356]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28cc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(data_t_1, data_t, unaware_prop, aware_art_vls_prop, diagnosis_rate_risk, dropout_rate_risk, prep_rate):\n",
    "\n",
    "    cost_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "\n",
    "    for risk in range(len(risk_groups)):\n",
    "        \n",
    "        total_pop_t_risk = np.apply_over_axes(np.sum, data_t[:,risk,:,0:21],[1,2]).reshape(num_jur,)\n",
    "        I_t_1 = np.apply_over_axes(np.sum, data_t_1[:,risk,:,1:21],[1,2]).reshape(num_jur,)\n",
    "        p_t_1_unaware = unaware_prop[:,risk]\n",
    "        p_t_1_art_vls = aware_art_vls_prop[:,risk]\n",
    "        delta_t = diagnosis_rate_risk[:,risk]\n",
    "        dropout_t = dropout_rate_risk[:,risk]\n",
    "        r_t_a_risk = delta_t*I_t_1*p_t_1_unaware \n",
    "        shi = shi_value(I_t_1, total_pop_t_risk)\n",
    "        x_t_a_risk = (r_t_a_risk - mu*I_t_1*p_t_1_unaware) / (theta*shi)\n",
    "        n_t_a_risk = mu*(total_pop_t_risk - I_t_1*p_t_1_unaware - x_t_a_risk) + x_t_a_risk*theta*(1-shi) \n",
    "        X_v_risk = tau*c_r_n + (1-tau)*c_c_n + n_n + (1-alpha)*c_add\n",
    "        Y_v_risk = tau*(c_r_p + n_r_p) + (1-tau)*(c_c_p + n_c_p) + c_cnf + (1-alpha)*c_add\n",
    "        \n",
    "        del_x = (x_t_a_risk - x_t_a_0[:,risk])/total_pop_t_risk\n",
    "        \n",
    "        O_v = O_v0*np.exp(del_x*W)\n",
    "        \n",
    "        X_f_cl_a = ((r_t_a_risk + n_t_a_risk)*alpha / m_cl)*f_c\n",
    "        X_f_ncl_a = ((r_t_a_risk + n_t_a_risk)*(1 - alpha) / m_nc)*f_nc\n",
    "        X_f_o_a = (x_t_a_risk / m_o)*f_o\n",
    "\n",
    "        cost_of_testing = r_t_a_risk*Y_v_risk + x_t_a_risk* O_v + n_t_a_risk*X_v_risk + X_f_cl_a + X_f_ncl_a + X_f_o_a\n",
    "\n",
    "        d_t_a_risk = (1 - dropout_t)*I_t_1*p_t_1_art_vls\n",
    "        del_p_art = p_t_1_art_vls - p_art_0[:,risk]\n",
    "        R_v_risk = R_art_0*np.exp(del_p_art*Y)\n",
    "        E_f_a = (d_t_a_risk / m_r)*f_r\n",
    "\n",
    "        cost_retention_in_care = d_t_a_risk*R_v_risk + E_f_a\n",
    "\n",
    "        if risk == 2:\n",
    "\n",
    "            prep_adherence_per_person_per_year = 1431\n",
    "            prep_medication_per_person_per_year = 12599\n",
    "\n",
    "            prep_cost = np.sum(data_t_1[:,risk,:,0], axis=1)*prep_rate[:,risk]* \\\n",
    "                            (prep_adherence_per_person_per_year + prep_medication_per_person_per_year)\n",
    "\n",
    "        else:\n",
    "            prep_cost = 0\n",
    "\n",
    "        cost_risk[:,risk] = cost_of_testing + cost_retention_in_care + prep_cost\n",
    "        \n",
    "    return dt*cost_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_l = 54000\n",
    "\n",
    "cd4_gt_350_index = (1,2,3,4,5,6,7,8,9,10,11,12)\n",
    "cd4_200_350_index = (13,14,15,16)\n",
    "cd_lt_200_index = (17,18,19,20)\n",
    "\n",
    "QALY_val_gt_350 = 0.935\n",
    "QALY_val_250_350 = 0.818\n",
    "QALY_val_lt_200 = 0.702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ac6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benefit(data_array):\n",
    "    L_t_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "\n",
    "    for risk in range(len(risk_groups)):\n",
    "\n",
    "        num_uninfected = np.sum(data_array[:,risk,:,0], axis=1)\n",
    "        num_over_350 = np.apply_over_axes(np.sum, data_array[:,risk,:,cd4_gt_350_index], [0,2]).reshape(num_jur,)\n",
    "        num_250_350 = np.apply_over_axes(np.sum, data_array[:,risk,:,cd4_200_350_index], [0,2]).reshape(num_jur,)\n",
    "        num_below_250 = np.apply_over_axes(np.sum, data_array[:,risk,:,cd_lt_200_index], [0,2]).reshape(num_jur,)\n",
    "\n",
    "        benefit_risk = 1*num_uninfected + QALY_val_gt_350*num_over_350 + QALY_val_250_350*num_250_350 + QALY_val_lt_200*num_below_250\n",
    "\n",
    "        L_t_risk[:,risk] = benefit_risk\n",
    "        \n",
    "    return c_l*dt*L_t_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(min_, max_, val):\n",
    "    new = min_ + (max_ - min_) * (val + 1)/ 2 \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30732ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_action_range(action):\n",
    "    for i in range(3):\n",
    "        if action[i] < -1:\n",
    "            action[i] = -1\n",
    "            \n",
    "        elif action[i] > 1:\n",
    "            action[i] = 1\n",
    "            \n",
    "        action[i] = get_action(-0.005, 0, action[i])\n",
    "        \n",
    "    for i in range(3,6):\n",
    "        if action[i] < -1:\n",
    "            action[i] = -1\n",
    "            \n",
    "        elif action[i] > 1:\n",
    "            action[i] = 1\n",
    "            \n",
    "        action[i] = get_action(0, 0.04, action[i])\n",
    "        \n",
    "    for i in range(6,8):\n",
    "        if action[i] < -1:\n",
    "            action[i] = -1\n",
    "            \n",
    "        elif action[i] > 1:\n",
    "            action[i] = 1\n",
    "            \n",
    "        action[i] = get_action(0,0, action[i])\n",
    "        \n",
    "    if action[8] < -1:\n",
    "        action[8] = -1\n",
    "        \n",
    "    elif action[8] > 1:\n",
    "        action[8] = 1\n",
    "        \n",
    "    action[8] = get_action(0,0.04, action[8])\n",
    "    \n",
    "    action = action.reshape(3,3)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafff8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_tile(action1, action2, action3, action4, action5, action6, action7, action8):\n",
    "    \n",
    "    action = np.zeros((num_jur, 3))\n",
    "    \n",
    "    action[cluster1_index,:] = action1\n",
    "    action[cluster2_index,:] = action2\n",
    "    action[cluster3_index,:] = action3\n",
    "    action[cluster4_index,:] = action4\n",
    "    action[cluster5_index,:] = action5\n",
    "    action[cluster6_index,:] = action6\n",
    "    action[cluster7_index,:] = action7\n",
    "    action[cluster8_index,:] = action8\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36dea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(current_state, action1, action2, action3, action4, action5, action6, action7, action8):\n",
    "    \n",
    "    data_array = current_state[0]\n",
    "    prep_values = current_state[9]\n",
    "    current_time = current_state[10]\n",
    "\n",
    "    action1 = change_action_range(action1)\n",
    "    action2 = change_action_range(action2)\n",
    "    action3 = change_action_range(action3)\n",
    "    action4 = change_action_range(action4)\n",
    "    action5 = change_action_range(action5)\n",
    "    action6 = change_action_range(action6)\n",
    "    action7 = change_action_range(action7)\n",
    "    action8 = change_action_range(action8)\n",
    "    \n",
    "    a_unaware1 = action1[0]\n",
    "    a_art1 = action1[1]\n",
    "    a_prep1 = action1[2]\n",
    "    \n",
    "    a_unaware2 = action2[0]\n",
    "    a_art2 = action2[1]\n",
    "    a_prep2 = action2[2]\n",
    "    \n",
    "    a_unaware3 = action3[0]\n",
    "    a_art3 = action3[1]\n",
    "    a_prep3 = action3[2]\n",
    "    \n",
    "    a_unaware4 = action4[0]\n",
    "    a_art4 = action4[1]\n",
    "    a_prep4 = action4[2]\n",
    "    \n",
    "    a_unaware5 = action5[0]\n",
    "    a_art5 = action5[1]\n",
    "    a_prep5 = action5[2]\n",
    "    \n",
    "    a_unaware6 = action6[0]\n",
    "    a_art6 = action6[1]\n",
    "    a_prep6 = action6[2]\n",
    "    \n",
    "    a_unaware7 = action7[0]\n",
    "    a_art7 = action7[1]\n",
    "    a_prep7 = action7[2]\n",
    "    \n",
    "    a_unaware8 = action8[0]\n",
    "    a_art8 = action8[1]\n",
    "    a_prep8 = action8[2]\n",
    "    \n",
    "    \n",
    "    a_unaware = action_tile(a_unaware1,a_unaware2,a_unaware3,a_unaware4,a_unaware5,a_unaware6,a_unaware7,a_unaware8)\n",
    "    a_art = action_tile(a_art1, a_art2, a_art3, a_art4, a_art5, a_art6, a_art7, a_art8)\n",
    "    a_prep = action_tile(a_prep1, a_prep2, a_prep3, a_prep4, a_prep5, a_prep6, a_prep7, a_prep8)\n",
    "    \n",
    "    #prep\n",
    "    prep_rate = prep_values + a_prep\n",
    "    \n",
    "    pop_susceptible_12_years = data_array[:,:,0,0]\n",
    "    \n",
    "    total_reward = 0\n",
    "    total_inf = 0\n",
    "    total_cost = 0\n",
    "    done = False\n",
    "    \n",
    "    total_pop, prevalence_prop, unaware_prop, aware_no_art_prop, aware_art_vls_prop,_ = \\\n",
    "        calculate_proportions(data_array, num_jur, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "\n",
    "    new_inf_per_month = new_infections_per_month(num_jur, data_array, new_infections_data, M_x1_y1_i, prep_rate)\n",
    "    death_per_month_risk_age_compartments = data_array*death_rate_risk_age_compartments*dt\n",
    "\n",
    "    diagnosis_rate_risk = diagnosis_rate(data_array, num_jur, a_unaware, unaware_index, number_of_risk_groups, new_inf_per_month, unaware_prop, death_per_month_risk_age_compartments)\n",
    "\n",
    "    dropout_rate_risk = dropout_rate(num_jur, a_art, ART_VLS_index, diagnosis_rate_risk, ltc_risk, gamma, number_of_risk_groups, data_array, new_inf_per_month, unaware_prop, aware_no_art_prop, aware_art_vls_prop, death_per_month_risk_age_compartments)\n",
    "\n",
    "    Q_matrix = q_matrix(num_jur, new_infections_data, diagnosis_rate_risk, dropout_rate_risk, ltc_risk)\n",
    "\n",
    "    Q_matrix_diagonal = q_mat_diag(Q_matrix, num_jur)\n",
    "    \n",
    "    \n",
    "    for i in range(12):\n",
    "\n",
    "        new_data = np.zeros((num_jur, number_of_risk_groups, age_groups, number_of_compartments))\n",
    "\n",
    "        data_t_1 = data_array.copy()\n",
    "\n",
    "        for risk in range(number_of_risk_groups):\n",
    "\n",
    "            #calculate flow of infected to diff compartments and subtract from that compartment\n",
    "            new_data[:,risk,:,:] = data_array[:,risk,:,:] + \\\n",
    "                                    np.matmul(data_array[:,risk,:,:], Q_matrix[:,risk,:,:]) - \\\n",
    "                                    np.matmul(data_array[:,risk,:,:], Q_matrix_diagonal[:,risk,:,:]) - \\\n",
    "                                    death_per_month_risk_age_compartments[:,risk,:,:]\n",
    "\n",
    "            #subtract from susceptible and add to acute unaware\n",
    "            new_data[:,risk,:,0] = new_data[:,risk,:,0] - new_inf_per_month[:,risk,:]\n",
    "            \n",
    "            new_data[:,risk,:,1] = new_data[:,risk,:,1] + new_inf_per_month[:,risk,:]\n",
    "\n",
    "            #add the total deaths to last column\n",
    "            new_data[:,risk,:,21] = np.sum(death_per_month_risk_age_compartments[:,risk,:,:], axis=2)\n",
    "\n",
    "\n",
    "        cost_per_month = cost(data_t_1, new_data, unaware_prop, aware_art_vls_prop, diagnosis_rate_risk, dropout_rate_risk, prep_rate)\n",
    "\n",
    "        benefit_per_month = benefit(new_data)\n",
    "\n",
    "        reward_per_month = benefit_per_month - cost_per_month\n",
    "\n",
    "        total_reward += reward_per_month\n",
    "        \n",
    "        total_cost += cost_per_month\n",
    "        \n",
    "        total_inf += new_inf_per_month\n",
    "\n",
    "        data_array = new_data.copy()\n",
    "    \n",
    "    new_pop_dist = aging(data_array, pop_susceptible_12_years*(1+pop_growth_rate)) # adding new pop\n",
    "    \n",
    "    new_state1,new_state2,new_state3,new_state4,new_state5,new_state6,new_state7,new_state8 = extract_state(new_pop_dist, prep_rate)\n",
    "                         \n",
    "    next_state = (new_pop_dist,new_state1,new_state2,new_state3,new_state4,new_state5,new_state6,new_state7,new_state8, prep_rate, current_time+1)\n",
    "    \n",
    "    reward_cluster1 = total_reward[cluster1_index,:]\n",
    "    reward_cluster2 = total_reward[cluster2_index,:]\n",
    "    reward_cluster3 = total_reward[cluster3_index,:]\n",
    "    reward_cluster4 = total_reward[cluster4_index,:]\n",
    "    reward_cluster5 = total_reward[cluster5_index,:]\n",
    "    reward_cluster6 = total_reward[cluster6_index,:]\n",
    "    reward_cluster7 = total_reward[cluster7_index,:]\n",
    "    reward_cluster8 = total_reward[cluster8_index,:]\n",
    "    \n",
    "    inf_cluster1 = total_inf[cluster1_index,:]\n",
    "    inf_cluster2 = total_inf[cluster2_index,:]\n",
    "    inf_cluster3 = total_inf[cluster3_index,:]\n",
    "    inf_cluster4 = total_inf[cluster4_index,:]\n",
    "    inf_cluster5 = total_inf[cluster5_index,:]\n",
    "    inf_cluster6 = total_inf[cluster6_index,:]\n",
    "    inf_cluster7 = total_inf[cluster7_index,:]\n",
    "    inf_cluster8 = total_inf[cluster8_index,:]\n",
    "    \n",
    "    total_cost1 = total_cost[cluster1_index,:]\n",
    "    total_cost2 = total_cost[cluster2_index,:]\n",
    "    total_cost3 = total_cost[cluster3_index,:]\n",
    "    total_cost4 = total_cost[cluster4_index,:]\n",
    "    total_cost5 = total_cost[cluster5_index,:]\n",
    "    total_cost6 = total_cost[cluster6_index,:]\n",
    "    total_cost7 = total_cost[cluster7_index,:]\n",
    "    total_cost8 = total_cost[cluster8_index,:]\n",
    "\n",
    "    reward1 = -np.sum(inf_cluster1) \n",
    "    reward2 = -np.sum(inf_cluster2)  \n",
    "    reward3 = -np.sum(inf_cluster3) \n",
    "    reward4 = -np.sum(inf_cluster4) \n",
    "    reward5 = -np.sum(inf_cluster5) \n",
    "    reward6 = -np.sum(inf_cluster6) \n",
    "    reward7 = -np.sum(inf_cluster7) \n",
    "    reward8 = -np.sum(inf_cluster8) \n",
    "    \n",
    "    if np.sum(total_cost1) > 2.00e6:\n",
    "        reward1 -= (np.sum(total_cost1) - 2.00e6)\n",
    "        \n",
    "    if np.sum(total_cost2) > 7.89e6:\n",
    "        reward2 -= (np.sum(total_cost2) - 7.89e6)\n",
    "        \n",
    "    if np.sum(total_cost3) > 2.00e6:\n",
    "        reward3 -= (np.sum(total_cost3) - 2.00e6)\n",
    "        \n",
    "    if np.sum(total_cost4) > 1.28e6:\n",
    "        reward4 -= (np.sum(total_cost4) - 1.28e6)\n",
    "        \n",
    "    if np.sum(total_cost5) > 2.00e6:\n",
    "        reward5 -= (np.sum(total_cost5) - 2.00e6)\n",
    "        \n",
    "    if np.sum(total_cost6) > 1.28e6 :\n",
    "        reward6 -= (np.sum(total_cost6) - 1.28e6)\n",
    "        \n",
    "    if np.sum(total_cost7) > 2.56e6:\n",
    "        reward7 -= (np.sum(total_cost7) - 2.56e6)\n",
    "        \n",
    "    if np.sum(total_cost8) > 3.53e7:\n",
    "        reward8 -= (np.sum(total_cost8) - 3.53e7) \n",
    "\n",
    "\n",
    "    if current_time+1 == 12:\n",
    "        done = True\n",
    "                         \n",
    "        \n",
    "    return next_state, reward1, reward2, reward3, reward4, reward5, reward6,reward7, reward8, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e337be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# set device to cpu or cuda\n",
    "device = torch.device('cpu')\n",
    "\n",
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")\n",
    "    \n",
    "print(\"============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d5ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.is_terminals = []\n",
    "    \n",
    "\n",
    "    def clear(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.is_terminals[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe77d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
    "\n",
    "        # actor\n",
    "        if has_continuous_action_space :\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Tanh()\n",
    "                        )\n",
    "        else:\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Softmax(dim=-1)\n",
    "                        )\n",
    "\n",
    "        \n",
    "        # critic\n",
    "        self.critic = nn.Sequential(\n",
    "                        nn.Linear(state_dim, 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64, 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64, 1)\n",
    "                    )\n",
    "        \n",
    "    def set_action_std(self, new_action_std):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "\n",
    "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        action_logprob = dist.log_prob(action)\n",
    "        \n",
    "        return action.detach(), action_logprob.detach()\n",
    "    \n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            action_var = self.action_var.expand_as(action_mean)\n",
    "            cov_mat = torch.diag_embed(action_var).to(device)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "            \n",
    "            # for single action continuous environments\n",
    "            if self.action_dim == 1:\n",
    "                action = action.reshape(-1, self.action_dim)\n",
    "\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "        state_values = self.critic(state)\n",
    "        \n",
    "        return action_logprobs, state_values, dist_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ec8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std_init\n",
    "\n",
    "        self.gamma_ = gamma_\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        \n",
    "        self.buffer = RolloutBuffer()\n",
    "\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
    "                    ])\n",
    "\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        \n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        \n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        # print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                # print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            # else:\n",
    "                # print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "\n",
    "        # print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "            \n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.item()\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "\n",
    "        # Monte Carlo estimate of returns\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma_ * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "            \n",
    "        # Normalizing the rewards\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
    "\n",
    "        # convert list to tensor\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "\n",
    "        \n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "\n",
    "            # Evaluating old actions and values\n",
    "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
    "\n",
    "            # match state_values tensor dimensions with rewards tensor\n",
    "            state_values = torch.squeeze(state_values)\n",
    "\n",
    "            # Finding the ratio (pi_theta / pi_theta__old)\n",
    "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
    "\n",
    "            # Finding Surrogate Loss\n",
    "            advantages = rewards - state_values.detach()   \n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "\n",
    "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
    "\n",
    "            # take gradient step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        # clear buffer\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    \n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "   \n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943dd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Training ###################################\n",
    "\n",
    "####### initialize environment hyperparameters ######\n",
    "\n",
    "action_std_decay_rate = 0.0046\n",
    "min_action_std = 0.05\n",
    "action_std_decay_freq = 1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "has_continuous_action_space = True\n",
    "\n",
    "max_ep_len = 12                   # max timesteps in one episode\n",
    "max_training_timesteps = 100000   # break training loop if timeteps > max_training_timesteps\n",
    "\n",
    "print_freq = max_ep_len * 10     # print avg reward in the interval (in num timesteps)\n",
    "log_freq = max_ep_len * 2       # log avg reward in the interval (in num timesteps)\n",
    "save_model_freq = 2000      # save model frequency (in num timesteps)\n",
    "plot_freq = 1200\n",
    "\n",
    "action_std = 0.4\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "################ PPO hyperparameters ################\n",
    "\n",
    "\n",
    "update_timestep = 120     # update policy every n timesteps\n",
    "K_epochs = 20               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma_ = 0.99                # discount factor\n",
    "\n",
    "lr_actor = 0.0003       # learning rate for actor network\n",
    "lr_critic = 0.0003       # learning rate for critic network\n",
    "\n",
    "random_seed = 10   # set random seed if required (0 = no random seed)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "env_name = 'HIV Jurisdiction'\n",
    "\n",
    "print(\"training environment name : \" + env_name)\n",
    "\n",
    "\n",
    "# state space dimension\n",
    "state_dim = 15\n",
    "\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = 9\n",
    "else:\n",
    "    action_dim = 1\n",
    "    \n",
    "###################### logging ######################\n",
    "\n",
    "#### log files for multiple runs are NOT overwritten\n",
    "\n",
    "log_dir = \"PPO_logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "log_dir = log_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "#### get number of log files in log directory\n",
    "run_num = 0\n",
    "current_num_files = next(os.walk(log_dir))[2]\n",
    "run_num = len(current_num_files)\n",
    "\n",
    "\n",
    "#### create new log file for each run \n",
    "log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
    "\n",
    "print(\"current logging run number for \" + env_name + \" : \", run_num)\n",
    "print(\"logging at : \" + log_f_name)\n",
    "\n",
    "\n",
    "run_num_pretrained = 0     \n",
    "\n",
    "directory = \"PPO_preTrained\"\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "directory = directory + '/' + env_name + '/' \n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "\n",
    "checkpoint_path1 = directory + 'Cluster1' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path2 = directory + 'Cluster2' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path3 = directory + 'Cluster3' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path4 = directory + 'Cluster4' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path5 = directory + 'Cluster5' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path6 = directory + 'Cluster6' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path7 = directory + 'Cluster7' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path8 = directory + 'Cluster8' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "\n",
    "print(\"save checkpoint path : \" + checkpoint_path1)\n",
    "\n",
    "############# print all hyperparameters #############\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"max training timesteps : \", max_training_timesteps)\n",
    "print(\"max timesteps per episode : \", max_ep_len)\n",
    "\n",
    "print(\"model saving frequency : \" + str(save_model_freq) + \" timesteps\")\n",
    "print(\"log frequency : \" + str(log_freq) + \" timesteps\")\n",
    "print(\"printing average reward over episodes in last : \" + str(print_freq) + \" timesteps\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"state space dimension : \", state_dim)\n",
    "print(\"action space dimension : \", action_dim)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "if has_continuous_action_space:\n",
    "    print(\"Initializing a continuous action space policy\")\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"starting std of action distribution : \", action_std)\n",
    "    print(\"decay rate of std of action distribution : \", action_std_decay_rate)\n",
    "    print(\"minimum std of action distribution : \", min_action_std)\n",
    "    print(\"decay frequency of std of action distribution : \" + str(action_std_decay_freq) + \" timesteps\")\n",
    "\n",
    "else:\n",
    "    print(\"Initializing a discrete action space policy\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"PPO update frequency : \" + str(update_timestep) + \" timesteps\") \n",
    "print(\"PPO K epochs : \", K_epochs)\n",
    "print(\"PPO epsilon clip : \", eps_clip)\n",
    "print(\"discount factor (gamma_) : \", gamma_)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"optimizer learning rate actor : \", lr_actor)\n",
    "print(\"optimizer learning rate critic : \", lr_critic)\n",
    "\n",
    "if random_seed:\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"setting random seed to \", random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# training procedure ################\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent1 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent2 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent3 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent4 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent5 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent6 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent7 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent8 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "# track total training time\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# logging file\n",
    "log_f = open(log_f_name,\"w+\")\n",
    "log_f.write('episode,timestep,reward\\n')\n",
    "\n",
    "# rew_list = []\n",
    "rew_list1 = []\n",
    "rew_list2 = []\n",
    "rew_list3 = []\n",
    "rew_list4 = []\n",
    "rew_list5 = []\n",
    "rew_list6 = []\n",
    "rew_list7 = []\n",
    "rew_list8 = []\n",
    "\n",
    "ep_rew_list1 = []\n",
    "ep_rew_list2 = []\n",
    "ep_rew_list3 = []\n",
    "ep_rew_list4 = []\n",
    "ep_rew_list5 = []\n",
    "ep_rew_list6 = []\n",
    "ep_rew_list7 = []\n",
    "ep_rew_list8 = []\n",
    "\n",
    "# printing and logging variables\n",
    "print_running_reward1 = 0\n",
    "print_running_reward2 = 0\n",
    "print_running_reward3 = 0\n",
    "print_running_reward4 = 0\n",
    "print_running_reward5 = 0\n",
    "print_running_reward6 = 0\n",
    "print_running_reward7 = 0\n",
    "print_running_reward8 = 0\n",
    "\n",
    "print_running_episodes = 0\n",
    "\n",
    "log_running_reward = 0\n",
    "log_running_episodes = 0\n",
    "\n",
    "time_step = 0\n",
    "i_episode = 0\n",
    "\n",
    "while time_step <= max_training_timesteps:\n",
    "    \n",
    "    state = initial_state(data_array_cluster,prep_values)\n",
    "\n",
    "    current_ep_reward1 = 0\n",
    "    current_ep_reward2 = 0\n",
    "    current_ep_reward3 = 0\n",
    "    current_ep_reward4 = 0\n",
    "    current_ep_reward5 = 0\n",
    "    current_ep_reward6 = 0\n",
    "    current_ep_reward7 = 0\n",
    "    current_ep_reward8 = 0\n",
    "       \n",
    "    for t in range(0, max_ep_len+1):\n",
    "        \n",
    "        # select action with policy\n",
    "\n",
    "        action1 = ppo_agent1.select_action(state[1].flatten())\n",
    "        action2 = ppo_agent2.select_action(state[2].flatten())\n",
    "        action3 = ppo_agent3.select_action(state[3].flatten())\n",
    "        action4 = ppo_agent4.select_action(state[4].flatten())\n",
    "        action5 = ppo_agent5.select_action(state[5].flatten())\n",
    "        action6 = ppo_agent6.select_action(state[6].flatten())\n",
    "        action7 = ppo_agent7.select_action(state[7].flatten())\n",
    "        action8 = ppo_agent8.select_action(state[8].flatten())\n",
    "\n",
    "\n",
    "        state,reward1,reward2,reward3,reward4,reward5,reward6,reward7,reward8,done  = step(state, action1, action2, action3, action4, action5, action6, action7, action8)\n",
    "\n",
    "        # saving reward and is_terminals\n",
    "        ppo_agent1.buffer.rewards.append(reward1)\n",
    "        ppo_agent1.buffer.is_terminals.append(done)\n",
    "        \n",
    "        ppo_agent2.buffer.rewards.append(reward2)\n",
    "        ppo_agent2.buffer.is_terminals.append(done)\n",
    "        \n",
    "        ppo_agent3.buffer.rewards.append(reward3)\n",
    "        ppo_agent3.buffer.is_terminals.append(done)\n",
    "        \n",
    "        ppo_agent4.buffer.rewards.append(reward4)\n",
    "        ppo_agent4.buffer.is_terminals.append(done)\n",
    "        \n",
    "        ppo_agent5.buffer.rewards.append(reward5)\n",
    "        ppo_agent5.buffer.is_terminals.append(done)\n",
    "        \n",
    "        ppo_agent6.buffer.rewards.append(reward6)\n",
    "        ppo_agent6.buffer.is_terminals.append(done)\n",
    "        \n",
    "        ppo_agent7.buffer.rewards.append(reward7)\n",
    "        ppo_agent7.buffer.is_terminals.append(done)\n",
    "        \n",
    "        ppo_agent8.buffer.rewards.append(reward8)\n",
    "        ppo_agent8.buffer.is_terminals.append(done)\n",
    "\n",
    "        \n",
    "        time_step +=1\n",
    "        current_ep_reward1 += reward1\n",
    "        current_ep_reward2 += reward2\n",
    "        current_ep_reward3 += reward3\n",
    "        current_ep_reward4 += reward4\n",
    "        current_ep_reward5 += reward5\n",
    "        current_ep_reward6 += reward6\n",
    "        current_ep_reward7 += reward7\n",
    "        current_ep_reward8 += reward8\n",
    "\n",
    "        \n",
    "        # update PPO agent\n",
    "        if time_step % update_timestep == 0:\n",
    "            ppo_agent1.update()\n",
    "            ppo_agent2.update()\n",
    "            ppo_agent3.update()\n",
    "            ppo_agent4.update()\n",
    "            ppo_agent5.update()\n",
    "            ppo_agent6.update()\n",
    "            ppo_agent7.update()\n",
    "            ppo_agent8.update()\n",
    "\n",
    "\n",
    "        if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
    "            ppo_agent1.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "            ppo_agent2.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "            ppo_agent3.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "            ppo_agent4.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "            ppo_agent5.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "            ppo_agent6.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "            ppo_agent7.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "            ppo_agent8.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "\n",
    "\n",
    "        # log in logging file\n",
    "        if time_step % log_freq == 0:\n",
    "\n",
    "            # log average reward till last episode\n",
    "            log_avg_reward = log_running_reward / log_running_episodes\n",
    "            log_avg_reward = round(log_avg_reward, 4)\n",
    "\n",
    "            log_f.write('{},{},{}\\n'.format(i_episode, time_step, log_avg_reward))\n",
    "            log_f.flush()\n",
    "\n",
    "            log_running_reward = 0\n",
    "            log_running_episodes = 0\n",
    "\n",
    "        # printing average reward\n",
    "        if time_step % print_freq == 0:\n",
    "\n",
    "            # print average reward till last episode\n",
    "            print_avg_reward1 = print_running_reward1 / print_running_episodes\n",
    "            print_avg_reward1 = round(print_avg_reward1, 2)\n",
    "            \n",
    "            print_avg_reward2 = print_running_reward2 / print_running_episodes\n",
    "            print_avg_reward2 = round(print_avg_reward2, 2)\n",
    "            \n",
    "            print_avg_reward3 = print_running_reward3 / print_running_episodes\n",
    "            print_avg_reward3 = round(print_avg_reward3, 2)\n",
    "\n",
    "            print_avg_reward4 = print_running_reward4 / print_running_episodes\n",
    "            print_avg_reward4 = round(print_avg_reward4, 2)\n",
    "            \n",
    "            print_avg_reward5 = print_running_reward5 / print_running_episodes\n",
    "            print_avg_reward5 = round(print_avg_reward5, 2)\n",
    "            \n",
    "            print_avg_reward6 = print_running_reward6 / print_running_episodes\n",
    "            print_avg_reward6 = round(print_avg_reward6, 2)\n",
    "\n",
    "            print_avg_reward7 = print_running_reward7 / print_running_episodes\n",
    "            print_avg_reward7 = round(print_avg_reward7, 2)\n",
    "            \n",
    "            print_avg_reward8 = print_running_reward8 / print_running_episodes\n",
    "            print_avg_reward8 = round(print_avg_reward8, 2)\n",
    "            \n",
    "\n",
    "            print(\"Agent1 => Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward1))\n",
    "            print(\"Agent2 => Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward2))\n",
    "            print(\"Agent3 => Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward3))\n",
    "            print(\"Agent4 => Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward4))\n",
    "            print(\"Agent5 => Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward5))\n",
    "            print(\"Agent6 => Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward6))\n",
    "            print(\"Agent7 => Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward7))\n",
    "            print(\"Agent8 => Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward8))\n",
    "           \n",
    "            rew_list1.append(print_avg_reward1)\n",
    "            rew_list2.append(print_avg_reward2)\n",
    "            rew_list3.append(print_avg_reward3)\n",
    "            rew_list4.append(print_avg_reward4)\n",
    "            rew_list5.append(print_avg_reward5)\n",
    "            rew_list6.append(print_avg_reward6)\n",
    "            rew_list7.append(print_avg_reward7)\n",
    "            rew_list8.append(print_avg_reward8)\n",
    "           \n",
    "            print_running_reward1 = 0\n",
    "            print_running_reward2 = 0\n",
    "            print_running_reward3 = 0\n",
    "            print_running_reward4 = 0\n",
    "            print_running_reward5 = 0\n",
    "            print_running_reward6 = 0\n",
    "            print_running_reward7 = 0\n",
    "            print_running_reward8 = 0\n",
    "  \n",
    "\n",
    "            print_running_episodes = 0\n",
    "            \n",
    "        if time_step % plot_freq == 0:\n",
    "            fig,ax = plt.subplots(2,4,sharex=False, sharey=False, figsize=(20,7))\n",
    "            fig.tight_layout(h_pad=3, w_pad=1)\n",
    "            ax[0][0].plot(range(len(rew_list1)), rew_list1)\n",
    "            ax[0][0].set_title('Rewards for Cluster 1',pad=12)\n",
    "            ax[0][1].plot(range(len(rew_list2)), rew_list2)\n",
    "            ax[0][1].set_title('Rewards for Cluster 2',pad=12)\n",
    "            ax[0][2].plot(range(len(rew_list3)), rew_list3)\n",
    "            ax[0][2].set_title('Rewards for Cluster 3',pad=12)\n",
    "            ax[0][3].plot(range(len(rew_list4)), rew_list4)\n",
    "            ax[0][3].set_title('Rewards for Cluster 4',pad=12)\n",
    "            ax[1][0].plot(range(len(rew_list5)), rew_list5)\n",
    "            ax[1][0].set_title('Rewards for Cluster 5',pad=12)\n",
    "            ax[1][1].plot(range(len(rew_list6)), rew_list6)\n",
    "            ax[1][1].set_title('Rewards for Cluster 6',pad=12)\n",
    "            ax[1][2].plot(range(len(rew_list7)), rew_list7)\n",
    "            ax[1][2].set_title('Rewards for Cluster 7',pad=12)\n",
    "            ax[1][3].plot(range(len(rew_list8)), rew_list8)\n",
    "            ax[1][3].set_title('Rewards for Cluster 8',pad=12)\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "        # save model weights\n",
    "        if time_step % save_model_freq == 0:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"saving model at : \" + checkpoint_path1)\n",
    "\n",
    "            ppo_agent1.save(checkpoint_path1)\n",
    "            ppo_agent2.save(checkpoint_path2)\n",
    "            ppo_agent3.save(checkpoint_path3)\n",
    "            ppo_agent4.save(checkpoint_path4)\n",
    "            ppo_agent5.save(checkpoint_path5)\n",
    "            ppo_agent6.save(checkpoint_path6)\n",
    "            ppo_agent7.save(checkpoint_path7)\n",
    "            ppo_agent8.save(checkpoint_path8)\n",
    "\n",
    "            print(\"model saved\")\n",
    "            print(\"Elapsed Time  : \", datetime.now().replace(microsecond=0) - start_time)\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            \n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print_running_reward1 += current_ep_reward1\n",
    "    print_running_reward2 += current_ep_reward2\n",
    "    print_running_reward3 += current_ep_reward3\n",
    "    print_running_reward4 += current_ep_reward4\n",
    "    print_running_reward5 += current_ep_reward5\n",
    "    print_running_reward6 += current_ep_reward6\n",
    "    print_running_reward7 += current_ep_reward7\n",
    "    print_running_reward8 += current_ep_reward8\n",
    "    \n",
    "    ep_rew_list1.append(current_ep_reward1)\n",
    "    ep_rew_list2.append(current_ep_reward2)\n",
    "    ep_rew_list3.append(current_ep_reward3)\n",
    "    ep_rew_list4.append(current_ep_reward4)\n",
    "    ep_rew_list5.append(current_ep_reward5)\n",
    "    ep_rew_list6.append(current_ep_reward6)\n",
    "    ep_rew_list7.append(current_ep_reward7)\n",
    "    ep_rew_list8.append(current_ep_reward8)\n",
    "\n",
    "    print_running_episodes += 1\n",
    "\n",
    "    log_running_reward += current_ep_reward1\n",
    "    log_running_episodes += 1\n",
    "\n",
    "    i_episode += 1\n",
    "\n",
    "\n",
    "log_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d5003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(current_state, action1, action2, action3, action4, action5, action6, action7, action8):\n",
    "    \n",
    "    data_array = current_state[0]\n",
    "    prep_values = current_state[9]\n",
    "    current_time = current_state[10]\n",
    "\n",
    "    action1 = change_action_range(action1)\n",
    "    action2 = change_action_range(action2)\n",
    "    action3 = change_action_range(action3)\n",
    "    action4 = change_action_range(action4)\n",
    "    action5 = change_action_range(action5)\n",
    "    action6 = change_action_range(action6)\n",
    "    action7 = change_action_range(action7)\n",
    "    action8 = change_action_range(action8)\n",
    "    \n",
    "    a_unaware1 = action1[0]\n",
    "    a_art1 = action1[1]\n",
    "    a_prep1 = action1[2]\n",
    "    \n",
    "    a_unaware2 = action2[0]\n",
    "    a_art2 = action2[1]\n",
    "    a_prep2 = action2[2]\n",
    "    \n",
    "    a_unaware3 = action3[0]\n",
    "    a_art3 = action3[1]\n",
    "    a_prep3 = action3[2]\n",
    "    \n",
    "    a_unaware4 = action4[0]\n",
    "    a_art4 = action4[1]\n",
    "    a_prep4 = action4[2]\n",
    "    \n",
    "    a_unaware5 = action5[0]\n",
    "    a_art5 = action5[1]\n",
    "    a_prep5 = action5[2]\n",
    "    \n",
    "    a_unaware6 = action6[0]\n",
    "    a_art6 = action6[1]\n",
    "    a_prep6 = action6[2]\n",
    "    \n",
    "    a_unaware7 = action7[0]\n",
    "    a_art7 = action7[1]\n",
    "    a_prep7 = action7[2]\n",
    "    \n",
    "    a_unaware8 = action8[0]\n",
    "    a_art8 = action8[1]\n",
    "    a_prep8 = action8[2]\n",
    "    \n",
    "    a_unaware = action_tile(a_unaware1,a_unaware2,a_unaware3,a_unaware4,a_unaware5,a_unaware6,a_unaware7,a_unaware8)\n",
    "    a_art = action_tile(a_art1, a_art2, a_art3, a_art4, a_art5, a_art6, a_art7, a_art8)\n",
    "    a_prep = action_tile(a_prep1, a_prep2, a_prep3, a_prep4, a_prep5, a_prep6, a_prep7, a_prep8)\n",
    "    \n",
    "    #prep\n",
    "    prep_rate = prep_values + a_prep\n",
    "    \n",
    "    pop_susceptible_12_years = data_array[:,:,0,0]\n",
    "    \n",
    "    total_reward = 0\n",
    "    total_cost = 0\n",
    "    total_inf = 0\n",
    "    done = False\n",
    "    \n",
    "    \n",
    "    total_pop, prevalence_prop, unaware_prop, aware_no_art_prop, aware_art_vls_prop,_ = \\\n",
    "        calculate_proportions(data_array, num_jur, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "\n",
    "    new_inf_per_month = new_infections_per_month(num_jur, data_array, new_infections_data, M_x1_y1_i, prep_rate)\n",
    "    death_per_month_risk_age_compartments = data_array*death_rate_risk_age_compartments*dt\n",
    "\n",
    "    diagnosis_rate_risk = diagnosis_rate(data_array, num_jur, a_unaware, unaware_index, number_of_risk_groups, new_inf_per_month, unaware_prop, death_per_month_risk_age_compartments)\n",
    "\n",
    "    dropout_rate_risk = dropout_rate(num_jur, a_art, ART_VLS_index, diagnosis_rate_risk, ltc_risk, gamma, number_of_risk_groups, data_array, new_inf_per_month, unaware_prop, aware_no_art_prop, aware_art_vls_prop, death_per_month_risk_age_compartments)\n",
    "\n",
    "    Q_matrix = q_matrix(num_jur, new_infections_data, diagnosis_rate_risk, dropout_rate_risk, ltc_risk)\n",
    "\n",
    "    Q_matrix_diagonal = q_mat_diag(Q_matrix, num_jur)\n",
    "    \n",
    "    \n",
    "    for i in range(12):\n",
    "\n",
    "        new_data = np.zeros((num_jur, number_of_risk_groups, age_groups, number_of_compartments))\n",
    "\n",
    "        data_t_1 = data_array.copy()\n",
    "\n",
    "        for risk in range(number_of_risk_groups):\n",
    "\n",
    "            #calculate flow of infected to diff compartments and subtract from that compartment\n",
    "            new_data[:,risk,:,:] = data_array[:,risk,:,:] + \\\n",
    "                                    np.matmul(data_array[:,risk,:,:], Q_matrix[:,risk,:,:]) - \\\n",
    "                                    np.matmul(data_array[:,risk,:,:], Q_matrix_diagonal[:,risk,:,:]) - \\\n",
    "                                    death_per_month_risk_age_compartments[:,risk,:,:]\n",
    "\n",
    "            #subtract from susceptible and add to acute unaware\n",
    "            new_data[:,risk,:,0] = new_data[:,risk,:,0] - new_inf_per_month[:,risk,:]\n",
    "            \n",
    "            new_data[:,risk,:,1] = new_data[:,risk,:,1] + new_inf_per_month[:,risk,:]\n",
    "\n",
    "            #add the total deaths to last column\n",
    "            new_data[:,risk,:,21] = np.sum(death_per_month_risk_age_compartments[:,risk,:,:], axis=2)\n",
    "\n",
    "\n",
    "        cost_per_month = cost(data_t_1, new_data, unaware_prop, aware_art_vls_prop, diagnosis_rate_risk, dropout_rate_risk, prep_rate)\n",
    "\n",
    "        benefit_per_month = benefit(new_data)\n",
    "\n",
    "        reward_per_month = benefit_per_month - cost_per_month\n",
    "\n",
    "        total_reward += reward_per_month\n",
    "        \n",
    "        total_cost += cost_per_month\n",
    "        \n",
    "        total_inf += new_inf_per_month\n",
    "\n",
    "        data_array = new_data.copy()\n",
    "    \n",
    "    new_pop_dist = aging(data_array, pop_susceptible_12_years*(1+pop_growth_rate)) # adding new pop\n",
    "    \n",
    "    new_state1,new_state2,new_state3,new_state4,new_state5,new_state6,new_state7,new_state8 = extract_state(new_pop_dist, prep_rate)\n",
    "                         \n",
    "    next_state = (new_pop_dist,new_state1,new_state2,new_state3,new_state4,new_state5,new_state6,new_state7,new_state8, prep_rate, current_time+1)\n",
    "    \n",
    "#     total_inf = 12*new_inf_per_month\n",
    "    total_inf = np.apply_over_axes(np.sum, total_inf, [2])\n",
    "    \n",
    "    reward_cluster1 = total_reward[cluster1_index,:]\n",
    "    reward_cluster2 = total_reward[cluster2_index,:]\n",
    "    reward_cluster3 = total_reward[cluster3_index,:]\n",
    "    reward_cluster4 = total_reward[cluster4_index,:]\n",
    "    reward_cluster5 = total_reward[cluster5_index,:]\n",
    "    reward_cluster6 = total_reward[cluster6_index,:]\n",
    "    reward_cluster7 = total_reward[cluster7_index,:]\n",
    "    reward_cluster8 = total_reward[cluster8_index,:]\n",
    "    \n",
    "    inf_cluster1 = total_inf[cluster1_index,:]\n",
    "    inf_cluster2 = total_inf[cluster2_index,:]\n",
    "    inf_cluster3 = total_inf[cluster3_index,:]\n",
    "    inf_cluster4 = total_inf[cluster4_index,:]\n",
    "    inf_cluster5 = total_inf[cluster5_index,:]\n",
    "    inf_cluster6 = total_inf[cluster6_index,:]\n",
    "    inf_cluster7 = total_inf[cluster7_index,:]\n",
    "    inf_cluster8 = total_inf[cluster8_index,:]\n",
    "    \n",
    "    total_cost1 = total_cost[cluster1_index,:]\n",
    "    total_cost2 = total_cost[cluster2_index,:]\n",
    "    total_cost3 = total_cost[cluster3_index,:]\n",
    "    total_cost4 = total_cost[cluster4_index,:]\n",
    "    total_cost5 = total_cost[cluster5_index,:]\n",
    "    total_cost6 = total_cost[cluster6_index,:]\n",
    "    total_cost7 = total_cost[cluster7_index,:]\n",
    "    total_cost8 = total_cost[cluster8_index,:]\n",
    "\n",
    "    reward1 = -np.sum(inf_cluster1) \n",
    "    reward2 = -np.sum(inf_cluster2)  \n",
    "    reward3 = -np.sum(inf_cluster3) \n",
    "    reward4 = -np.sum(inf_cluster4) \n",
    "    reward5 = -np.sum(inf_cluster5) \n",
    "    reward6 = -np.sum(inf_cluster6) \n",
    "    reward7 = -np.sum(inf_cluster7) \n",
    "    reward8 = -np.sum(inf_cluster8) \n",
    "    \n",
    "    if np.sum(total_cost1) > 2.00e6:\n",
    "        reward1 -= (np.sum(total_cost1) - 2.00e6)\n",
    "        \n",
    "    if np.sum(total_cost2) > 7.89e6:\n",
    "        reward2 -= (np.sum(total_cost2) - 7.89e6)\n",
    "        \n",
    "    if np.sum(total_cost3) > 2.00e6:\n",
    "        reward3 -= (np.sum(total_cost3) - 2.00e6)\n",
    "        \n",
    "    if np.sum(total_cost4) > 1.28e6:\n",
    "        reward4 -= (np.sum(total_cost4) - 1.28e6)\n",
    "        \n",
    "    if np.sum(total_cost5) > 2.00e6:\n",
    "        reward5 -= (np.sum(total_cost5) - 2.00e6)\n",
    "        \n",
    "    if np.sum(total_cost6) > 1.28e6 :\n",
    "        reward6 -= (np.sum(total_cost6) - 1.28e6)\n",
    "        \n",
    "    if np.sum(total_cost7) > 2.56e6:\n",
    "        reward7 -= (np.sum(total_cost7) - 2.56e6)\n",
    "        \n",
    "    if np.sum(total_cost8) > 3.53e7:\n",
    "        reward8 -= (np.sum(total_cost8) - 3.53e7) \n",
    "\n",
    "    \n",
    "    total_cost = np.sum(total_cost, axis=1)\n",
    "\n",
    "    if current_time+1 == 12:\n",
    "        done = True\n",
    "    \n",
    "    t_p, p_p, u_p, a_no_art_p, a_art_vls_p,vls_p = \\\n",
    "        calculate_proportions(data_array, num_jur, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "\n",
    "        \n",
    "    return next_state,reward1,reward2,reward3,reward4,reward5,reward6,reward7,reward8,done,total_inf,diagnosis_rate_risk,dropout_rate_risk, u_p, a_art_vls_p,vls_p,prep_rate, total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b17db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"============================================================================================\")\n",
    "\n",
    "env_name = \"HIV Jurisdiction\"\n",
    "has_continuous_action_space = True\n",
    "max_ep_len = 1000           # max timesteps in one episode\n",
    "action_std = 0.05           \n",
    "\n",
    "total_test_episodes = 10    # total num of testing episodes\n",
    "\n",
    "K_epochs = 20               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma_ = 0.99                # discount factor\n",
    "\n",
    "lr_actor = 0.0003           # learning rate for actor\n",
    "lr_critic = 0.0003           # learning rate for critic\n",
    "\n",
    "#####################################################\n",
    "\n",
    "# state space dimension\n",
    "state_dim = 15\n",
    "\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = 9\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent1 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent2 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent3 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent4 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent5 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent6 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent7 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "ppo_agent8 = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma_, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "# preTrained weights directory\n",
    "\n",
    "random_seed = 10           #### set this to load a particular checkpoint trained on random seed\n",
    "if random_seed:\n",
    "#     print(\"--------------------------------------------------------------------------------------------\")\n",
    "#     print(\"setting random seed to \", random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "#     env.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "\n",
    "run_num_pretrained = 0      #### set this to load a particular checkpoint num\n",
    "\n",
    "directory = \"PPO_preTrained\" + '/' + env_name + '/' \n",
    "# directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
    "# checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path1 = directory + 'Cluster1' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path2 = directory + 'Cluster2' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path3 = directory + 'Cluster3' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path4 = directory + 'Cluster4' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path5 = directory + 'Cluster5' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path6 = directory + 'Cluster6' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path7 = directory + 'Cluster7' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "checkpoint_path8 = directory + 'Cluster8' + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "\n",
    "print(\"loading network from : \" + checkpoint_path1)\n",
    "ppo_agent1.load(checkpoint_path1)\n",
    "\n",
    "print(\"loading network from : \" + checkpoint_path2)\n",
    "ppo_agent2.load(checkpoint_path2)\n",
    "\n",
    "print(\"loading network from : \" + checkpoint_path3)\n",
    "ppo_agent3.load(checkpoint_path3)\n",
    "\n",
    "print(\"loading network from : \" + checkpoint_path4)\n",
    "ppo_agent4.load(checkpoint_path4)\n",
    "\n",
    "print(\"loading network from : \" + checkpoint_path5)\n",
    "ppo_agent5.load(checkpoint_path5)\n",
    "\n",
    "print(\"loading network from : \" + checkpoint_path6)\n",
    "ppo_agent6.load(checkpoint_path6)\n",
    "\n",
    "print(\"loading network from : \" + checkpoint_path7)\n",
    "ppo_agent7.load(checkpoint_path7)\n",
    "\n",
    "print(\"loading network from : \" + checkpoint_path8)\n",
    "ppo_agent8.load(checkpoint_path8)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "test_running_reward = 0\n",
    "reward_list = []\n",
    "\n",
    "diag_list = []\n",
    "drop_list = []\n",
    "prep_list = []\n",
    "inf_list = []\n",
    "cost_list = []\n",
    "unaware_list = []\n",
    "art_vls_list = []\n",
    "vls_list = []\n",
    "\n",
    "episode_reward_list1 = []\n",
    "episode_reward_list2 = []\n",
    "episode_reward_list3 = []\n",
    "episode_reward_list4 = []\n",
    "episode_reward_list5 = []\n",
    "episode_reward_list6 = []\n",
    "episode_reward_list7 = []\n",
    "episode_reward_list8 = []\n",
    "\n",
    "\n",
    "for ep in range(1):\n",
    "    ep_reward = 0\n",
    "    \n",
    "    state = initial_state(data_array_cluster,prep_values)\n",
    "\n",
    "    current_ep_reward1 = 0\n",
    "    current_ep_reward2 = 0\n",
    "    current_ep_reward3 = 0\n",
    "    current_ep_reward4 = 0\n",
    "    current_ep_reward5 = 0\n",
    "    current_ep_reward6 = 0\n",
    "    current_ep_reward7 = 0\n",
    "    current_ep_reward8 = 0\n",
    "\n",
    "\n",
    "    for t in range(1, max_ep_len+1):\n",
    "        \n",
    "        action1 = ppo_agent1.select_action(state[1].flatten())\n",
    "        action2 = ppo_agent2.select_action(state[2].flatten())\n",
    "        action3 = ppo_agent3.select_action(state[3].flatten())\n",
    "        action4 = ppo_agent4.select_action(state[4].flatten())\n",
    "        action5 = ppo_agent5.select_action(state[5].flatten())\n",
    "        action6 = ppo_agent6.select_action(state[6].flatten())\n",
    "        action7 = ppo_agent7.select_action(state[7].flatten())\n",
    "        action8 = ppo_agent8.select_action(state[8].flatten())\n",
    "\n",
    "#         print(change_action_range(action1))\n",
    "        state,reward1,reward2,reward3,reward4,reward5,reward6,reward7,reward8,done,total_inf,diag_rate,drop_rate,un_prop,art_prop,vls_prop,prep_rate,total_cost =test_step(state, action1, action2, action3, action4, action5, action6, action7, action8)\n",
    "        \n",
    "        diag_list.append(diag_rate)\n",
    "        drop_list.append(drop_rate)\n",
    "        prep_list.append(prep_rate)\n",
    "        inf_list.append(total_inf)\n",
    "        cost_list.append(total_cost)        \n",
    "        unaware_list.append(un_prop)\n",
    "        art_vls_list.append(art_prop)\n",
    "        vls_list.append(vls_prop)\n",
    "\n",
    "        current_ep_reward1 += reward1\n",
    "        current_ep_reward2 += reward2\n",
    "        current_ep_reward3 += reward3\n",
    "        current_ep_reward4 += reward4\n",
    "        current_ep_reward5 += reward5\n",
    "        current_ep_reward6 += reward6\n",
    "        current_ep_reward7 += reward7\n",
    "        current_ep_reward8 += reward8\n",
    "\n",
    "#         ltc_risk += ltc_increment\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # clear buffer\n",
    "\n",
    "    ppo_agent1.buffer.clear()\n",
    "    ppo_agent2.buffer.clear()\n",
    "    ppo_agent3.buffer.clear()\n",
    "    ppo_agent4.buffer.clear()\n",
    "    ppo_agent5.buffer.clear()\n",
    "    ppo_agent6.buffer.clear()\n",
    "    ppo_agent7.buffer.clear()\n",
    "    ppo_agent8.buffer.clear()\n",
    "\n",
    "#     reward_list.append(ep_reward)\n",
    "\n",
    "    episode_reward_list1.append(current_ep_reward1)\n",
    "    episode_reward_list2.append(current_ep_reward2)\n",
    "    episode_reward_list3.append(current_ep_reward3)\n",
    "    episode_reward_list4.append(current_ep_reward4)\n",
    "    episode_reward_list5.append(current_ep_reward5)\n",
    "    episode_reward_list6.append(current_ep_reward6)\n",
    "    episode_reward_list7.append(current_ep_reward7)\n",
    "    episode_reward_list8.append(current_ep_reward8)\n",
    "\n",
    "    test_running_reward +=  current_ep_reward1\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(current_ep_reward1, 2)))\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(current_ep_reward2, 2)))\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(current_ep_reward3, 2)))\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(current_ep_reward4, 2)))\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(current_ep_reward5, 2)))\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(current_ep_reward6, 2)))\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(current_ep_reward7, 2)))\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(current_ep_reward8, 2)))\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inf_dict = {}\n",
    "\n",
    "for i in range(8):\n",
    "    lis1 = []\n",
    "    lis2 = []\n",
    "    lis3 = []\n",
    "    \n",
    "    for j in range(12):\n",
    "        lis1.append(inf_list[j][i][0][0])\n",
    "        lis2.append(inf_list[j][i][1][0])\n",
    "        lis3.append(inf_list[j][i][2][0])\n",
    "                    \n",
    "    new_inf_dict[jur_name[i]]=[lis1,lis2,lis3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b09444",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inf_dict = {}\n",
    "\n",
    "for jur in jur_name:\n",
    "    a = new_inf_dict[jur][0]\n",
    "    b = new_inf_dict[jur][1]\n",
    "    c = new_inf_dict[jur][2]\n",
    "    \n",
    "    lis = list(np.array(a)+np.array(b)+np.array(c))\n",
    "    \n",
    "    total_inf_dict[jur] = lis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
